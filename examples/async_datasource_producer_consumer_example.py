#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚æ­¥æ•°æ®æº-ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ‰§è¡Œå™¨ä½¿ç”¨ç¤ºä¾‹

æ•°æ®æº: loader + splitter
ç”Ÿäº§è€…: embedding
æ¶ˆè´¹è€…: indexer
"""

import asyncio
import logging
import os
import sys
import time

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag.pipeline.async_datasource_producer_consumer_executor import (
    AsyncDataSourceProducerConsumerPipelineExecutor,
)
from utils.config import config
from utils.logger import get_logger, setup_logging

setup_logging(level="INFO")
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("openai._base_client").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("elastic_transport").setLevel(logging.WARNING)
logging.getLogger("elastic_transport.transport").setLevel(logging.WARNING)
logging.getLogger("elasticsearch").setLevel(logging.WARNING)


async def async_example():
    """å¼‚æ­¥è°ƒç”¨ç¤ºä¾‹"""
    logger = get_logger(__name__)
    logger.info("=== å¼‚æ­¥æ•°æ®æº-ç”Ÿäº§è€…-æ¶ˆè´¹è€…Pipelineç¤ºä¾‹ ===\n")

    # ç›´æ¥ä½¿ç”¨ utils.configï¼Œæ— éœ€ dict() åŒ…è£…
    pipeline_config = config.datasource_producer_consumer_pipeline

    # åˆ›å»ºå¼‚æ­¥æ‰§è¡Œå™¨
    executor = AsyncDataSourceProducerConsumerPipelineExecutor(pipeline_config)

    # å¼‚æ­¥æ‰§è¡Œ
    start_time = time.time()
    result = await executor.run_async({})
    end_time = time.time()

    logger.info("\nğŸ¯ å¼‚æ­¥æ‰§è¡Œå®Œæˆï¼")
    logger.info(f"æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
    logger.info(f"å¤„ç†ç»“æœ: {result}")


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ç¤ºä¾‹
    print("è¿è¡Œå¼‚æ­¥ç¤ºä¾‹...")
    asyncio.run(async_example())

