import os
from typing import Any, Dict, List

import openai

from ..base import Component
from .base_embedding import BaseEmbedding
from utils.logger import get_logger  # ğŸ‘ˆ æ·»åŠ loggerå¯¼å…¥


class OpenAIEmbedding(BaseEmbedding):
    """OpenAI embeddingå®¢æˆ·ç«¯ï¼Œæ”¯æŒå•æ¡å’Œæ‰¹é‡æ–‡æœ¬embedding"""

    def __init__(
        self,
        model: str,
        api_key: str,
        api_base: str,
        batch_size: int,
        dimensions: int = None,
        timeout: int = 60,
        max_retries: int = 3,
    ):
        """åˆå§‹åŒ–OpenAI embeddingå®¢æˆ·ç«¯

        Args:
            model: ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹åç§°
            api_key: OpenAI APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è·å–
            api_base: OpenAI APIåŸºç¡€URLï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            batch_size: æ‰¹å¤„ç†å¤§å°
            dimensions: åµŒå…¥å‘é‡ç»´åº¦ï¼Œå¯é€‰å‚æ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        # ç§»é™¤å¼ºåˆ¶è¦æ±‚dimensionså‚æ•°çš„æ£€æŸ¥
        super().__init__(dimensions=dimensions)
        
        # ğŸ‘ˆ æ·»åŠ loggeråˆå§‹åŒ–
        self.logger = get_logger(f"{__name__}.OpenAIEmbedding")
        
        # è®¾ç½®APIå¯†é’¥
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·é€šè¿‡å‚æ•°ä¼ å…¥æˆ–è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡"
            )

        # è®¾ç½®APIåŸºç¡€URL
        self.api_base = api_base

        # è®¾ç½®æ¨¡å‹å’Œæ‰¹å¤„ç†å‚æ•°
        self.model = model
        self.batch_size = batch_size
        self.timeout = timeout
        self.max_retries = max_retries

        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self._init_client()

    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        client_kwargs = {
            "api_key": self.api_key,
            "timeout": self.timeout,
            "max_retries": self.max_retries,
        }

        if self.api_base:
            client_kwargs["base_url"] = self.api_base

        self.client = openai.OpenAI(**client_kwargs)

    def embed_text(self, text: str) -> List[float]:
        """å¯¹å•æ¡æ–‡æœ¬è¿›è¡Œembedding
    
        Args:
            text: éœ€è¦åµŒå…¥çš„æ–‡æœ¬
    
        Returns:
            List[float]: åµŒå…¥å‘é‡
        """
        if not text or not text.strip():
            raise ValueError(f"ä¸èƒ½å¯¹ç©ºæ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ï¼Œè¾“å…¥æ–‡æœ¬: '{text}'")
    
        # è®°å½•è°ƒè¯•ä¿¡æ¯
        if self.logger:
            self.logger.debug(f"æ­£åœ¨å‘é‡åŒ–æ–‡æœ¬: '{text[:100]}...' (é•¿åº¦: {len(text)})")
            self.logger.debug(f"ä½¿ç”¨æ¨¡å‹: {self.model}, APIåŸºç¡€URL: {self.api_base}")
    
        # ç®€å•çš„è¯·æ±‚å‚æ•°ï¼Œä¸ç®¡dimensions
        request_params = {
            "model": self.model,
            "input": text
        }
    
        try:
            response = self.client.embeddings.create(**request_params)
            
            # æ£€æŸ¥å“åº”æ•°æ®
            if not response.data:
                raise ValueError(f"OpenAI API è¿”å›ç©ºæ•°æ®ï¼Œæ¨¡å‹: {self.model}, æ–‡æœ¬é•¿åº¦: {len(text)}")
            
            if not response.data[0].embedding:
                raise ValueError(f"OpenAI API è¿”å›ç©ºå‘é‡ï¼Œæ¨¡å‹: {self.model}, å“åº”: {response}")
            
            embedding = response.data[0].embedding
            if self.logger:
                self.logger.debug(f"æˆåŠŸè·å–å‘é‡ï¼Œç»´åº¦: {len(embedding)}")
            
            return embedding
            
        except openai.APIStatusError as e:
            # æ•è·HTTPçŠ¶æ€ç é”™è¯¯
            error_msg = f"OpenAI API è¿”å›é200çŠ¶æ€ç : {e.status_code}\n" \
                       f"é”™è¯¯ç±»å‹: {e.type}\n" \
                       f"é”™è¯¯æ¶ˆæ¯: {e.message}\n" \
                       f"æ¨¡å‹: {self.model}\n" \
                       f"APIåŸºç¡€URL: {self.api_base}\n" \
                       f"æ–‡æœ¬é•¿åº¦: {len(text)}\n" \
                       f"æ–‡æœ¬å†…å®¹: '{text[:200]}...'"
            if self.logger:
                self.logger.error(error_msg)
            raise ValueError(error_msg) from e
        except openai.APIConnectionError as e:
            # æ•è·è¿æ¥é”™è¯¯
            error_msg = f"OpenAI API è¿æ¥å¤±è´¥: {e}\n" \
                       f"æ¨¡å‹: {self.model}\n" \
                       f"APIåŸºç¡€URL: {self.api_base}\n" \
                       f"æ–‡æœ¬é•¿åº¦: {len(text)}\n" \
                       f"æ–‡æœ¬å†…å®¹: '{text[:200]}...'"
            if self.logger:
                self.logger.error(error_msg)
            raise ValueError(error_msg) from e
        except Exception as e:
            error_msg = f"OpenAI embedding è°ƒç”¨å¤±è´¥: {e}\n" \
                       f"æ¨¡å‹: {self.model}\n" \
                       f"APIåŸºç¡€URL: {self.api_base}\n" \
                       f"æ–‡æœ¬é•¿åº¦: {len(text)}\n" \
                       f"æ–‡æœ¬å†…å®¹: '{text[:200]}...'"
            if self.logger:
                self.logger.error(error_msg)
            raise ValueError(error_msg) from e

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """å¯¹å¤šæ¡æ–‡æœ¬è¿›è¡Œæ‰¹é‡embedding
    
        Args:
            texts: éœ€è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
    
        Returns:
            List[List[float]]: åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
    
        # è¿‡æ»¤æ‰ç©ºæ–‡æœ¬ï¼Œç›´æ¥å¿½ç•¥
        filtered_texts = [text for text in texts if text.strip()]
        
        if not filtered_texts:
            return []
        
        results = []
        # æ‰¹é‡å¤„ç†
        for i in range(0, len(filtered_texts), self.batch_size):
            batch = filtered_texts[i:i + self.batch_size]
            
            # ç®€å•çš„è¯·æ±‚å‚æ•°ï¼Œä¸ç®¡dimensions
            request_params = {
                "model": self.model,
                "input": batch
            }
    
            try:
                response = self.client.embeddings.create(**request_params)
                batch_embeddings = [data.embedding for data in response.data]
                results.extend(batch_embeddings)
            except openai.APIStatusError as e:
                # æ•è·HTTPçŠ¶æ€ç é”™è¯¯
                error_msg = f"æ‰¹é‡embeddingè¯·æ±‚è¿”å›é200çŠ¶æ€ç : {e.status_code}\n" \
                           f"é”™è¯¯ç±»å‹: {e.type}\n" \
                           f"é”™è¯¯æ¶ˆæ¯: {e.message}\n" \
                           f"æ¨¡å‹: {self.model}\n" \
                           f"APIåŸºç¡€URL: {self.api_base}\n" \
                           f"æ‰¹æ¬¡å¤§å°: {len(batch)}"
                if self.logger:
                    self.logger.error(error_msg)
                raise ValueError(error_msg) from e
            except openai.APIConnectionError as e:
                # æ•è·è¿æ¥é”™è¯¯
                error_msg = f"æ‰¹é‡embeddingè¯·æ±‚è¿æ¥å¤±è´¥: {e}\n" \
                           f"æ¨¡å‹: {self.model}\n" \
                           f"APIåŸºç¡€URL: {self.api_base}\n" \
                           f"æ‰¹æ¬¡å¤§å°: {len(batch)}"
                if self.logger:
                    self.logger.error(error_msg)
                raise ValueError(error_msg) from e
            except Exception as e:
                error_msg = f"æ‰¹é‡embeddingè¯·æ±‚å¤±è´¥: {e}\n" \
                           f"æ¨¡å‹: {self.model}\n" \
                           f"APIåŸºç¡€URL: {self.api_base}\n" \
                           f"æ‰¹æ¬¡å¤§å°: {len(batch)}"
                if self.logger:
                    self.logger.error(error_msg)
                raise ValueError(error_msg) from e
    
        return results


class OpenAIEmbeddingComponent(Component):
    """OpenAI Embeddingç»„ä»¶"""

    def __init__(self, name: str, config: Dict[str, Any]):
        super().__init__(name, config)
        self.embedding_client = None
        # ğŸ‘ˆ æ·»åŠ ç¼“å­˜æœºåˆ¶
        self.text_cache = []  # ç¼“å­˜å¾…å¤„ç†çš„æ–‡æœ¬
        self.doc_cache = []   # ç¼“å­˜å¯¹åº”çš„æ–‡æ¡£å¯¹è±¡
        self.cache_size = config.get("batch_size", 100)  # ç¼“å­˜å¤§å°
        self.force_flush = False  # å¼ºåˆ¶åˆ·æ–°æ ‡å¿—

    def _do_initialize(self):
        """åˆå§‹åŒ–embeddingå®¢æˆ·ç«¯"""
        try:
            # ä»é…ç½®åˆ›å»ºembeddingå®¢æˆ·ç«¯
            self.embedding_client = OpenAIEmbedding(
                model=self.config.get("model"),
                api_key=self.config.get("api_key"),
                api_base=self.config.get("api_base"),
                batch_size=self.config.get("batch_size", 10),
                dimensions=self.config.get("dimensions"),  # å…è®¸ä¸ºNone
                timeout=self.config.get("timeout", 60),
                max_retries=self.config.get("max_retries", 3),
            )

            if self.debug:
                dims = self.embedding_client.get_dimensions()
                if dims is not None:
                    self.logger.debug(
                        f"OpenAI Embeddingç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œç»´åº¦: {dims}"
                    )
                else:
                    self.logger.debug(
                        "OpenAI Embeddingç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œç»´åº¦å°†åœ¨é¦–æ¬¡è°ƒç”¨æ—¶ç¡®å®š"
                    )

        except Exception as e:
            self.logger.error(f"OpenAI Embeddingç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£ï¼Œæ·»åŠ å‘é‡åŒ–ç»“æœï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰"""
        try:
            documents = data.get("documents", [])
    
            if not documents:
                return data
    
            # å°†æ–°æ–‡æ¡£æ·»åŠ åˆ°ç¼“å­˜
            for doc in documents:
                content = doc.get("content", doc.get("text", ""))
                self.text_cache.append(content)
                self.doc_cache.append(doc)
    
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†ç¼“å­˜
            if len(self.text_cache) >= self.cache_size or self.force_flush:
                return self._process_cached_texts()
            else:
                return {"documents": []}
    
        except Exception as e:
            self.logger.error(f"âŒ æ–‡æ¡£å‘é‡åŒ–å¤±è´¥: {e}")
            raise

    def _process_cached_texts(self) -> Dict[str, Any]:
        """å¤„ç†ç¼“å­˜ä¸­çš„æ–‡æœ¬"""
        if not self.text_cache:
            return {"documents": []}

        # æ‰¹é‡å‘é‡åŒ–
        embeddings = self.embedding_client.embed_texts(self.text_cache)

        # å°†å‘é‡æ·»åŠ åˆ°å¯¹åº”æ–‡æ¡£ä¸­
        for doc, embedding in zip(self.doc_cache, embeddings):
            doc["content_vector"] = embedding

        # å‡†å¤‡è¿”å›æ•°æ®
        result_docs = self.doc_cache.copy()
        
        # æ¸…ç©ºç¼“å­˜
        self.text_cache.clear()
        self.doc_cache.clear()
        self.force_flush = False
        return {"documents": result_docs}

    def flush_cache(self):
        """å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼ˆåœ¨pipelineç»“æŸæ—¶è°ƒç”¨ï¼‰"""
        self.force_flush = True
        if self.text_cache:
            return self._process_cached_texts()
        return {"documents": []}

