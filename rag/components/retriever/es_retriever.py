from typing import Any, Dict, List, Optional

from elasticsearch import Elasticsearch

from utils.config import config

from ..embedding.embedding_factory import EmbeddingFactory
from .base_retriever import BaseRetrieverComponent


class ESRetrieverComponent(BaseRetrieverComponent):
    """Elasticsearchæ£€ç´¢å™¨ç»„ä»¶"""

    def __init__(self, name: str, config: Dict[str, Any]):
        super().__init__(name, config)

        if Elasticsearch is None:
            raise ImportError("è¯·å®‰è£…elasticsearchåŒ…: pip install elasticsearch")

        # å‘é‡æ£€ç´¢ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ0-1èŒƒå›´ï¼‰
        self.vector_similarity_threshold = config.get(
            "vector_similarity_threshold", 0.1
        )
        # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸå‚æ•°å
        if "similarity_threshold" in config:
            self.vector_similarity_threshold = config["similarity_threshold"]

        # BM25æ–‡æœ¬æ£€ç´¢åˆ†æ•°é˜ˆå€¼ï¼ˆBM25åˆ†æ•°ï¼Œé€šå¸¸>1ï¼‰
        self.bm25_score_threshold = config.get("bm25_score_threshold", 20.0)

        # ä¼˜å…ˆæ£€ç´¢çš„chunk_level
        self.preferred_chunk_level = config.get("preferred_chunk_level")

        # ESé…ç½®
        self.host = config.get("host", "localhost")
        self.port = config.get("port", 9200)
        self.username = config.get("username")
        self.password = config.get("password")
        self.use_ssl = config.get("use_ssl", False)
        self.verify_certs = config.get("verify_certs", False)

        # æ£€ç´¢é…ç½®
        self.search_type = config.get("search_type", "text")  # text, vector, hybrid
        self.embedding_config = config.get("embedding", {})

        # Small2Bigæ£€ç´¢é…ç½®
        self.enable_small2big = config.get("enable_small2big", False)
        small2big_config = config.get("small2big_config", {})
        # ä¿å­˜small2big_configä¸ºå®ä¾‹å±æ€§
        self.small2big_config = small2big_config
        self.small_chunk_top_k = small2big_config.get("small_chunk_top_k", 20)
        self.final_top_k = small2big_config.get("final_top_k", 10)
        self.expansion_strategy = small2big_config.get(
            "expansion_strategy", "parent_expansion"
        )
        self.similarity_threshold_small = small2big_config.get(
            "similarity_threshold_small", 0.6
        )
        self.score_fusion_method = small2big_config.get("score_fusion_method", "max")
        self.enable_score_normalization = small2big_config.get(
            "enable_score_normalization", True
        )
        self.diversity_threshold = small2big_config.get("diversity_threshold", 0.8)
        self.max_small_chunks_per_big = small2big_config.get(
            "max_small_chunks_per_big", 5
        )

        # RRFé…ç½®
        self.fusion_method = config.get("fusion_method", "weighted")  # weighted, rrf
        self.rrf_k = config.get("rrf_k", 60)  # RRFå‚æ•°
        self.text_weight = config.get("text_weight", 1.0)  # æ–‡æœ¬æ£€ç´¢æƒé‡
        self.vector_weight = config.get("vector_weight", 1.2)  # å‘é‡æ£€ç´¢æƒé‡

        # æ·»åŠ è‡ªå®šä¹‰æŸ¥è¯¢å­—æ®µæ”¯æŒ
        self.search_fields = config.get(
            "search_fields",
            {
                "content": 2.0,
                "metadata.title": 1.5,
                "metadata.category": 1.0,
                "metadata.tags": 1.0,
            },
        )

        # æ·»åŠ åˆ†æå™¨é…ç½®è¯»å–
        self.analyzer_config = config.get("analyzer_config", {})
        self.search_analyzer = self.analyzer_config.get(
            "search_analyzer", "ik_search_analyzer"
        )
        self.index_analyzer = self.analyzer_config.get("index_analyzer", "ik_analyzer")

        # æ·»åŠ é«˜äº®é…ç½®è¯»å–
        self.highlight_config = config.get("highlight_config", {})
        self.default_highlight_settings = {
            "require_field_match": self.highlight_config.get(
                "require_field_match", False
            ),
            "fragment_size": self.highlight_config.get("fragment_size", 150),
            "number_of_fragments": self.highlight_config.get("number_of_fragments", 3),
            "pre_tags": self.highlight_config.get("pre_tags", ["<mark>"]),
            "post_tags": self.highlight_config.get("post_tags", ["</mark>"]),
        }

        # å†…éƒ¨çŠ¶æ€
        self.client = None
        self.embedding_client = None

    def _do_initialize(self):
        """åˆå§‹åŒ–ESå®¢æˆ·ç«¯å’Œembeddingå®¢æˆ·ç«¯"""
        try:
            self._connect_to_index()

            # å¦‚æœéœ€è¦å‘é‡æ£€ç´¢ï¼Œåˆå§‹åŒ–embeddingå®¢æˆ·ç«¯
            if self.search_type in ["vector", "hybrid"]:
                self._init_embedding_client()

            if self.debug:
                self.logger.debug(
                    f"ESæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ£€ç´¢ç±»å‹: {self.search_type}, èåˆæ–¹æ³•: {self.fusion_method}"
                )

        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–ESæ£€ç´¢å™¨å¤±è´¥: {e}")
            raise

    def _connect_to_index(self):
        """è¿æ¥åˆ°ESç´¢å¼•"""
        try:
            # æ„å»ºè¿æ¥é…ç½®
            if self.use_ssl:
                hosts = [f"https://{self.host}:{self.port}"]
            else:
                hosts = [f"http://{self.host}:{self.port}"]

            es_config = {
                "hosts": hosts,
                "verify_certs": self.verify_certs,
            }

            if self.username and self.password:
                es_config["basic_auth"] = (self.username, self.password)

            self.client = Elasticsearch(**es_config)

            # æµ‹è¯•è¿æ¥
            if not self.client.ping():
                raise ConnectionError("æ— æ³•è¿æ¥åˆ°Elasticsearch")

            if self.debug:
                self.logger.debug(f"æˆåŠŸè¿æ¥åˆ°Elasticsearch: {self.host}:{self.port}")

        except Exception as e:
            self.logger.error(f"è¿æ¥Elasticsearchå¤±è´¥: {e}")
            raise

    def _init_embedding_client(self):
        """åˆå§‹åŒ–embeddingå®¢æˆ·ç«¯"""
        try:
            embedding_type = self.embedding_config.get("type", "hf")
            if embedding_type == "hf":
                emb_cfg = config.embeddings.clients.hf
                self.embedding_client = EmbeddingFactory.create(
                    "hf", model_name=emb_cfg.model_name
                )
            elif embedding_type == "openai":
                # ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°
                self.embedding_client = EmbeddingFactory.create(
                    "openai",
                    model=self.embedding_config.get("model"),
                    api_key=self.embedding_config.get("api_key"),
                    api_base=self.embedding_config.get("api_base"),
                    batch_size=self.embedding_config.get("batch_size", 10),
                    dimensions=self.embedding_config.get("dimensions"),
                    timeout=self.embedding_config.get("timeout", 60),
                    max_retries=self.embedding_config.get("max_retries", 3),
                )
            elif embedding_type == "bge_embedding":
                emb_cfg = config.embeddings.clients.bge_embedding
                self.embedding_client = EmbeddingFactory.create(
                    "bge_embedding", api_url=emb_cfg.api_url
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„embeddingç±»å‹: {embedding_type}")

            if self.debug:
                self.logger.debug(f"Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ: {embedding_type}")

        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–embeddingå®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise

    def retrieve(
        self, query: str, top_k: Optional[int] = None, **kwargs
    ) -> List[Dict[str, Any]]:
        """æ£€ç´¢æ–‡æ¡£"""
        use_top_k = top_k or self.top_k

        try:
            if self.debug:
                self.logger.debug(
                    f"ğŸ” å¼€å§‹ESæ£€ç´¢ - æŸ¥è¯¢: '{query}', æ£€ç´¢ç±»å‹: {self.search_type}, Top-K: {use_top_k}"
                )

            # å¦‚æœå¯ç”¨Small2Bigæ£€ç´¢
            if self.enable_small2big:
                return self._small2big_search(query, use_top_k)

            # åŸæœ‰æ£€ç´¢é€»è¾‘
            if self.search_type == "text":
                return self._text_search(query, use_top_k)
            elif self.search_type == "vector":
                return self._vector_search(query, use_top_k)
            elif self.search_type == "hybrid":
                return self._hybrid_search(query, use_top_k)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ£€ç´¢ç±»å‹: {self.search_type}")

        except Exception as e:
            import traceback

            self.logger.error(f"æ£€ç´¢å¤±è´¥: {e}\n{traceback.format_exc()}")
            return []

    def _small2big_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """Small2Bigæ£€ç´¢ç­–ç•¥å®ç°"""
        if self.debug:
            self.logger.info(f"ğŸ” å¼€å§‹Small2Bigæ£€ç´¢ - æŸ¥è¯¢: '{query}'")
            self.logger.info(
                f"   ç¬¬ä¸€é˜¶æ®µ: æ£€ç´¢Small Chunk (ç›®æ ‡æ•°é‡: {self.small_chunk_top_k})"
            )

        # ç¬¬ä¸€é˜¶æ®µï¼šæ£€ç´¢Small Chunk
        small_chunks = self._search_small_chunks(query, self.small_chunk_top_k)

        if not small_chunks:
            self.logger.warning("âš ï¸ Small Chunkæ£€ç´¢æ— ç»“æœ")
            return []

        if self.debug:
            self.logger.info(
                f"   âœ… Small Chunkæ£€ç´¢å®Œæˆï¼Œè·å¾— {len(small_chunks)} ä¸ªç»“æœ"
            )
            self.logger.info("   ç¬¬äºŒé˜¶æ®µ: æ‰©å±•åˆ°Big Chunkå¹¶èåˆåˆ†æ•°")

        # ç¬¬äºŒé˜¶æ®µï¼šæ ¹æ®ç­–ç•¥æ‰©å±•åˆ°Big Chunk
        big_chunks = self._expand_to_big_chunks(small_chunks)

        if self.debug:
            self.logger.info(f"   âœ… æ‰©å±•å®Œæˆï¼Œè·å¾— {len(big_chunks)} ä¸ªBig Chunk")
            self.logger.info("   ç¬¬ä¸‰é˜¶æ®µ: åˆ†æ•°èåˆå’Œé‡æ’åº")

        # ç¬¬ä¸‰é˜¶æ®µï¼šåˆ†æ•°èåˆå’Œé‡æ’åº
        final_results = self._fuse_and_rerank(big_chunks, top_k)

        if self.debug:
            self.logger.info(
                f"ğŸ¯ Small2Bigæ£€ç´¢å®Œæˆï¼Œæœ€ç»ˆè¿”å› {len(final_results)} ä¸ªç»“æœ"
            )
            for i, result in enumerate(final_results[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                self.logger.debug(
                    f"   #{i} ID: {result['id']}, åˆ†æ•°: {result['score']:.4f}, æ¥æºSmall Chunkæ•°: {result.get('source_small_chunks_count', 1)}"
                )

        return final_results

    def _build_highlight_fields(self) -> Dict[str, Any]:
        """åŠ¨æ€æ„å»ºé«˜äº®å­—æ®µé…ç½®"""
        highlight_fields = {}

        # ä»é…ç½®ä¸­è·å–å­—æ®µç‰¹å®šçš„é«˜äº®è®¾ç½®
        field_configs = self.highlight_config.get("fields", {})

        # ä¸ºæ‰€æœ‰æœç´¢å­—æ®µæ·»åŠ é«˜äº®é…ç½®
        for field in self.search_fields.keys():
            if field in field_configs:
                # ä½¿ç”¨å­—æ®µç‰¹å®šé…ç½®
                field_config = field_configs[field].copy()
                highlight_fields[field] = field_config
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                highlight_fields[field] = {
                    "fragment_size": self.default_highlight_settings["fragment_size"],
                    "number_of_fragments": self.default_highlight_settings[
                        "number_of_fragments"
                    ],
                    "pre_tags": self.default_highlight_settings["pre_tags"],
                    "post_tags": self.default_highlight_settings["post_tags"],
                }

        # ç‰¹åˆ«å¤„ç† content_jieba å­—æ®µï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ†æå™¨
        if "content_jieba" in highlight_fields:
            highlight_fields["content_jieba"]["analyzer"] = self.search_analyzer

        if self.debug:
            self.logger.debug(f"ğŸ¨ æ„å»ºçš„é«˜äº®å­—æ®µé…ç½®: {highlight_fields}")

        return highlight_fields

    def _search_small_chunks(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æ£€ç´¢Small Chunk - åŠ¨æ€æ£€æµ‹ç‰ˆæœ¬"""
        # åŠ¨æ€æ£€æµ‹chunk_levelå­—æ®µè·¯å¾„å’Œå€¼
        chunk_level_info = self._detect_chunk_level_config()

        if not chunk_level_info:
            self.logger.warning("æ— æ³•æ£€æµ‹chunk_levelé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            chunk_level_filter = {"term": {"metadata.chunk_level": 2}}  # å›é€€åˆ°é»˜è®¤å€¼
        else:
            chunk_level_filter = {
                "term": {
                    chunk_level_info["field_path"]: chunk_level_info[
                        "small_chunk_level"
                    ]
                }
            }

        if self.debug:
            self.logger.debug(f"ğŸ” Small Chunkè¿‡æ»¤æ¡ä»¶: {chunk_level_filter}")

        if self.search_type == "hybrid":
            # æ··åˆæ£€ç´¢Small Chunk
            return self._hybrid_search_with_filter(query, top_k, chunk_level_filter)
        elif self.search_type == "vector":
            return self._vector_search_with_filter(query, top_k, chunk_level_filter)
        else:
            return self._text_search_with_filter(query, top_k, chunk_level_filter)

    def _expand_to_big_chunks(
        self, small_chunks: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """å°†Small Chunkæ‰©å±•åˆ°Big Chunk"""
        big_chunk_groups = {}

        if self.debug:
            self.logger.debug(
                f"ğŸ”„ å¼€å§‹æ‰©å±• {len(small_chunks)} ä¸ªsmall chunksåˆ°big chunks"
            )

        for i, small_chunk in enumerate(small_chunks):
            metadata = small_chunk.get("metadata", {})
            chunk_level = metadata.get("chunk_level", 0)

            if self.debug:
                self.logger.debug(f"ğŸ“‹ å¤„ç†small chunk #{i+1}: {small_chunk['id']}")
                self.logger.debug(f"   ğŸ“Š åˆ†æ•°: {small_chunk['score']:.6f}")
                self.logger.debug(f"   ğŸ·ï¸  å…ƒæ•°æ®: {metadata}")

            if self.expansion_strategy == "parent_expansion":
                # é€šè¿‡parent_idæ‰©å±•
                parent_id = metadata.get("parent_id")
                if self.debug:
                    self.logger.debug(f"   ğŸ”— parent_id: {parent_id}")

                # Level 0 chunk æœ¬èº«å°±æ˜¯ big chunkï¼Œæ— éœ€æ‰©å±•
                if chunk_level == 0:
                    # Level 0 chunkæœ¬èº«å°±æ˜¯big chunk
                    big_chunk_groups[small_chunk["id"]] = {
                        "small_chunks": [small_chunk],
                        "big_chunk_data": small_chunk,  # ä½¿ç”¨è‡ªèº«
                        "max_score": small_chunk["score"],
                        "avg_score": small_chunk["score"],
                    }
                    if self.debug:
                        self.logger.debug(
                            f"âœ… Level 0 chunk {small_chunk['id']} æœ¬èº«å°±æ˜¯big chunkï¼Œç›´æ¥ä½¿ç”¨"
                        )
                elif parent_id:
                    if parent_id not in big_chunk_groups:
                        big_chunk_groups[parent_id] = {
                            "small_chunks": [],
                            "max_score": 0,
                            "avg_score": 0,
                            "big_chunk_data": None,
                        }
                        if self.debug:
                            self.logger.debug(f"   âœ… åˆ›å»ºæ–°çš„big chunkç»„: {parent_id}")

                    big_chunk_groups[parent_id]["small_chunks"].append(small_chunk)
                    big_chunk_groups[parent_id]["max_score"] = max(
                        big_chunk_groups[parent_id]["max_score"], small_chunk["score"]
                    )
                    if self.debug:
                        self.logger.debug(
                            f"   âœ… æ·»åŠ åˆ°big chunkç»„ {parent_id}ï¼Œå½“å‰æœ€é«˜åˆ†æ•°: {big_chunk_groups[parent_id]['max_score']:.6f}"
                        )
                else:
                    # é™çº§ç­–ç•¥ï¼šä½¿ç”¨small chunkæœ¬èº«
                    if self.debug:
                        self.logger.warning(
                            f"âš ï¸ Level {chunk_level} chunk {small_chunk['id']} ç¼ºå°‘parent_idï¼Œé™çº§ä½¿ç”¨small chunk"
                        )

                    fallback_id = f"fallback_{small_chunk['id']}"
                    big_chunk_groups[fallback_id] = {
                        "small_chunks": [small_chunk],
                        "big_chunk_data": {
                            "id": fallback_id,
                            "content": small_chunk["content"],
                            "metadata": {**metadata, "is_fallback": True},
                        },
                        "max_score": small_chunk["score"],
                        "avg_score": small_chunk["score"],
                    }

            elif self.expansion_strategy == "root_expansion":
                # é€šè¿‡root_idæ‰©å±•åˆ°æœ€å¤§ç²’åº¦
                root_id = metadata.get("root_id")
                if self.debug:
                    self.logger.debug(f"   ğŸ”— root_id: {root_id}")

                if root_id:
                    if root_id not in big_chunk_groups:
                        big_chunk_groups[root_id] = {
                            "small_chunks": [],
                            "max_score": 0,
                            "avg_score": 0,
                            "big_chunk_data": None,
                        }
                        if self.debug:
                            self.logger.debug(f"   âœ… åˆ›å»ºæ–°çš„big chunkç»„: {root_id}")

                    big_chunk_groups[root_id]["small_chunks"].append(small_chunk)
                    big_chunk_groups[root_id]["max_score"] = max(
                        big_chunk_groups[root_id]["max_score"], small_chunk["score"]
                    )
                    if self.debug:
                        self.logger.debug(
                            f"   âœ… æ·»åŠ åˆ°big chunkç»„ {root_id}ï¼Œå½“å‰æœ€é«˜åˆ†æ•°: {big_chunk_groups[root_id]['max_score']:.6f}"
                        )
                else:
                    if self.debug:
                        self.logger.warning(
                            f"   âŒ small chunk {small_chunk['id']} ç¼ºå°‘root_idï¼Œå°†è¢«ä¸¢å¼ƒ"
                        )

        if self.debug:
            self.logger.debug(
                f"ğŸ“Š æ‰©å±•ç»Ÿè®¡: åˆ›å»ºäº† {len(big_chunk_groups)} ä¸ªbig chunkç»„"
            )
            for big_chunk_id, group_data in big_chunk_groups.items():
                self.logger.debug(
                    f"   ğŸ“¦ Big chunkç»„ {big_chunk_id}: {len(group_data['small_chunks'])} ä¸ªsmall chunks"
                )

        # è·å–Big Chunkçš„å®Œæ•´å†…å®¹
        successful_groups = 0
        for big_chunk_id, group_data in big_chunk_groups.items():
            if self.debug:
                self.logger.debug(f"ğŸ” æ­£åœ¨è·å–big chunkå†…å®¹: {big_chunk_id}")

            big_chunk_content = self._get_big_chunk_content(big_chunk_id)
            if big_chunk_content:
                group_data["big_chunk_data"] = big_chunk_content
                successful_groups += 1

                # è®¡ç®—å¹³å‡åˆ†æ•°
                scores = [chunk["score"] for chunk in group_data["small_chunks"]]
                group_data["avg_score"] = sum(scores) / len(scores)

                if self.debug:
                    self.logger.debug(
                        f"   âœ… æˆåŠŸè·å–big chunk {big_chunk_id}ï¼ŒåŒ…å« {len(group_data['small_chunks'])} ä¸ªsmall chunks"
                    )
                    self.logger.debug(
                        f"   ğŸ“Š åˆ†æ•°ç»Ÿè®¡ - æœ€é«˜: {group_data['max_score']:.6f}, å¹³å‡: {group_data['avg_score']:.6f}"
                    )
            else:
                if self.debug:
                    self.logger.warning(
                        f"   âŒ æ— æ³•è·å–big chunk {big_chunk_id} çš„å†…å®¹ï¼Œè¯¥ç»„å°†è¢«ä¸¢å¼ƒ"
                    )
                    # æ˜¾ç¤ºè¢«ä¸¢å¼ƒçš„small chunks
                    for small_chunk in group_data["small_chunks"]:
                        self.logger.warning(
                            f"      ğŸ—‘ï¸  ä¸¢å¼ƒsmall chunk: {small_chunk['id']} (åˆ†æ•°: {small_chunk['score']:.6f})"
                        )

        if self.debug:
            self.logger.debug(
                f"ğŸ¯ æ‰©å±•å®Œæˆ: {successful_groups}/{len(big_chunk_groups)} ä¸ªbig chunkç»„æˆåŠŸè·å–å†…å®¹"
            )

        return big_chunk_groups

    def _get_big_chunk_content(self, big_chunk_id: str) -> Optional[Dict[str, Any]]:
        """è·å–Big Chunkçš„å®Œæ•´å†…å®¹"""
        try:
            # ä½¿ç”¨ .keyword å­—æ®µè¿›è¡Œç²¾ç¡®åŒ¹é…
            search_body = {
                "query": {"term": {"metadata.chunk_id.keyword": big_chunk_id}},
                "size": 1,
            }

            response = self.client.search(index=self.index_name, body=search_body)

            if response["hits"]["total"]["value"] > 0:
                hit = response["hits"]["hits"][0]
                return {
                    "id": hit["_id"],
                    "content": hit["_source"].get("content", ""),
                    "metadata": hit["_source"].get("metadata", {}),
                }
        except Exception as e:
            if self.debug:
                self.logger.warning(f"è·å–Big Chunk {big_chunk_id} å¤±è´¥: {e}")
        return None

    def _fuse_and_rerank(
        self, big_chunk_groups: Dict, top_k: int
    ) -> List[Dict[str, Any]]:
        """èåˆåˆ†æ•°å¹¶é‡æ–°æ’åº"""
        results = []

        for big_chunk_id, group_data in big_chunk_groups.items():
            if not group_data["big_chunk_data"]:
                continue

            # æ ¹æ®èåˆæ–¹æ³•è®¡ç®—æœ€ç»ˆåˆ†æ•°
            if self.score_fusion_method == "max":
                final_score = group_data["max_score"]
            elif self.score_fusion_method == "avg":
                final_score = group_data["avg_score"]
            elif self.score_fusion_method == "weighted_avg":
                # åŠ æƒå¹³å‡ï¼Œåˆ†æ•°è¶Šé«˜æƒé‡è¶Šå¤§
                scores = [chunk["score"] for chunk in group_data["small_chunks"]]
                weights = [score / sum(scores) for score in scores]
                final_score = sum(
                    score * weight for score, weight in zip(scores, weights)
                )
            else:
                final_score = group_data["max_score"]

            result = {
                "id": big_chunk_id,
                "score": final_score,
                "content": group_data["big_chunk_data"]["content"],
                "metadata": group_data["big_chunk_data"]["metadata"],
                "recall_source": "small2big",
                "source_small_chunks": group_data["small_chunks"],
                "source_small_chunks_count": len(group_data["small_chunks"]),
                "max_small_score": group_data["max_score"],
                "avg_small_score": group_data["avg_score"],
                "fusion_method": self.score_fusion_method,
            }

            results.append(result)

        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top_k
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]

    def _hybrid_search_with_filter(
        self, query: str, top_k: int, filter_clause: Dict
    ) -> List[Dict[str, Any]]:
        """å¸¦è¿‡æ»¤æ¡ä»¶çš„æ··åˆæ£€ç´¢ - æ”¯æŒå·®å¼‚åŒ–chunk level"""
        if not self.embedding_client:
            raise RuntimeError("æ··åˆæ£€ç´¢éœ€è¦embeddingå®¢æˆ·ç«¯")

        vector_field = self.embedding_config.get("field_name", "embedding")
        query_embedding = self.embedding_client.embed_text(query)

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å·®å¼‚åŒ–æ£€ç´¢
        enable_differential = self.small2big_config.get(
            "enable_differential_retrieval", False
        )

        if enable_differential:
            # å·®å¼‚åŒ–æ£€ç´¢ï¼šå‘é‡æ£€ç´¢ä½¿ç”¨small chunkï¼Œæ–‡æœ¬æ£€ç´¢ä½¿ç”¨big chunk
            vector_chunk_level = self.small2big_config.get("vector_chunk_level", 2)
            text_chunk_level = self.small2big_config.get("text_chunk_level", 0)

            # ğŸ”§ ä¿®æ­£ï¼šä¸ºä¸åŒæ£€ç´¢ç±»å‹æ„å»ºç‹¬ç«‹çš„è¿‡æ»¤æ¡ä»¶
            # å‘é‡æ£€ç´¢è¿‡æ»¤æ¡ä»¶ï¼ˆsmall chunkï¼‰
            vector_filter_clauses = [
                {"term": {"metadata.chunk_level": vector_chunk_level}}
            ]

            # æ–‡æœ¬æ£€ç´¢è¿‡æ»¤æ¡ä»¶ï¼ˆbig chunkï¼‰
            text_filter_clauses = [{"term": {"metadata.chunk_level": text_chunk_level}}]

            if self.debug:
                self.logger.info(
                    f"ğŸ”„ å·®å¼‚åŒ–æ£€ç´¢ç­–ç•¥ï¼šå‘é‡æ£€ç´¢chunk_level={vector_chunk_level}ï¼Œæ–‡æœ¬æ£€ç´¢chunk_level={text_chunk_level}"
                )
        else:
            # ä¼ ç»Ÿæ–¹å¼ï¼šä½¿ç”¨ç›¸åŒçš„è¿‡æ»¤æ¡ä»¶
            vector_filter_clauses = text_filter_clauses = [filter_clause]

        # æ–‡æœ¬æ£€ç´¢éƒ¨åˆ†ï¼ˆBM25 + big chunkï¼‰
        should_queries = []
        for field, boost in self.search_fields.items():
            should_queries.append(
                {
                    "match": {
                        field: {
                            "query": query,
                            "boost": boost,
                            "analyzer": self.search_analyzer,
                        }
                    }
                }
            )

        # ğŸ†• æ·»åŠ é«˜äº®å­—æ®µé…ç½®
        highlight_fields = self._build_highlight_fields()

        text_search_body = {
            "query": {
                "bool": {
                    "should": should_queries,
                    "filter": text_filter_clauses,
                    "minimum_should_match": 1,
                }
            },
            # ğŸ†• æ·»åŠ é«˜äº®é…ç½®
            "highlight": {
                "fields": highlight_fields,
                "require_field_match": self.default_highlight_settings[
                    "require_field_match"
                ],
            },
            "size": top_k * 2,
        }

        # å‘é‡æ£€ç´¢éƒ¨åˆ†ï¼ˆå‘é‡ + small chunkï¼‰
        vector_search_body = {
            "knn": {
                "field": vector_field,
                "query_vector": query_embedding,
                "k": top_k * 2,
                "num_candidates": top_k * 4,
                "filter": {"bool": {"filter": vector_filter_clauses}},
            },
            "size": top_k * 2,
        }

        if self.debug:
            self.logger.debug(f"ğŸ” æ‰§è¡Œæ–‡æœ¬æ£€ç´¢æŸ¥è¯¢ä½“: {text_search_body}")
            self.logger.debug(f"ğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢æŸ¥è¯¢ä½“: {vector_search_body}")

        # æ‰§è¡Œæ£€ç´¢
        text_response = self.client.search(index=self.index_name, body=text_search_body)
        vector_response = self.client.search(
            index=self.index_name, body=vector_search_body
        )

        if self.debug:
            # æ‰“å°åŸå§‹æ£€ç´¢ç»“æœç»Ÿè®¡
            text_total = text_response["hits"]["total"]
            vector_total = vector_response["hits"]["total"]
            text_hits = len(text_response["hits"]["hits"])
            vector_hits = len(vector_response["hits"]["hits"])

            if isinstance(text_total, dict):
                text_total_count = text_total.get("value", 0)
            else:
                text_total_count = text_total

            if isinstance(vector_total, dict):
                vector_total_count = vector_total.get("value", 0)
            else:
                vector_total_count = vector_total

            self.logger.debug(
                f"ğŸ“Š æ–‡æœ¬æ£€ç´¢åŸå§‹ç»“æœ: æ€»å‘½ä¸­={text_total_count}, è¿”å›={text_hits}"
            )
            self.logger.debug(
                f"ğŸ“Š å‘é‡æ£€ç´¢åŸå§‹ç»“æœ: æ€»å‘½ä¸­={vector_total_count}, è¿”å›={vector_hits}"
            )

            # æ‰“å°æ–‡æœ¬æ£€ç´¢çš„å‰å‡ ä¸ªç»“æœ
            if text_hits > 0:
                self.logger.debug("ğŸ“ æ–‡æœ¬æ£€ç´¢å‰3ä¸ªç»“æœ:")
                for i, hit in enumerate(text_response["hits"]["hits"][:3]):
                    self.logger.debug(
                        f"  {i+1}. ID={hit['_id']}, Score={hit['_score']:.4f}, chunk_level={hit['_source'].get('metadata', {}).get('chunk_level', 'N/A')}"
                    )
            else:
                self.logger.debug("âŒ æ–‡æœ¬æ£€ç´¢æ— ç»“æœï¼")

            # æ‰“å°å‘é‡æ£€ç´¢çš„å‰å‡ ä¸ªç»“æœ
            if vector_hits > 0:
                self.logger.debug("ğŸ¯ å‘é‡æ£€ç´¢å‰3ä¸ªç»“æœ:")
                for i, hit in enumerate(vector_response["hits"]["hits"][:3]):
                    self.logger.debug(
                        f"  {i+1}. ID={hit['_id']}, Score={hit['_score']:.4f}, chunk_level={hit['_source'].get('metadata', {}).get('chunk_level', 'N/A')}"
                    )
            else:
                self.logger.debug("âŒ å‘é‡æ£€ç´¢æ— ç»“æœï¼")

            # ä½¿ç”¨ç°æœ‰çš„èåˆæ–¹æ³•
            if self.fusion_method == "rrf":
                return self._merge_hybrid_results_with_rrf(
                    text_response, vector_response, query, top_k
                )
            else:
                return self._merge_hybrid_results_with_highlights(
                    text_response, vector_response, query, top_k
                )
        # ä½¿ç”¨ç°æœ‰çš„èåˆæ–¹æ³•
        if self.fusion_method == "rrf":
            return self._merge_hybrid_results_with_rrf(
                text_response, vector_response, query, top_k
            )
        else:
            return self._merge_hybrid_results_with_highlights(
                text_response, vector_response, query, top_k
            )

    def _text_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æ–‡æœ¬æ£€ç´¢"""
        # åŠ¨æ€æ„å»ºæŸ¥è¯¢å­—æ®µ
        should_queries = []

        for field, boost in self.search_fields.items():
            should_queries.append(
                {
                    "match": {
                        field: {
                            "query": query,
                            "boost": boost,
                            "analyzer": self.search_analyzer,
                        }
                    }
                }
            )

        # ğŸ”§ ä½¿ç”¨æ–°çš„é«˜äº®å­—æ®µæ„å»ºæ–¹æ³•
        highlight_fields = self._build_highlight_fields()

        search_body = {
            "query": {"bool": {"should": should_queries}},
            "highlight": {
                "fields": highlight_fields,
                "require_field_match": self.default_highlight_settings[
                    "require_field_match"
                ],
            },
            "size": top_k,
        }

        if self.debug:
            self.logger.debug(f"ğŸ“ æ–‡æœ¬æ£€ç´¢æŸ¥è¯¢ä½“: {search_body}")

        response = self.client.search(index=self.index_name, body=search_body)
        return self._format_results_with_highlights(response, query, "æ–‡æœ¬æ£€ç´¢")

    def _vector_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """å‘é‡æ£€ç´¢"""
        if not self.embedding_client:
            raise RuntimeError("å‘é‡æ£€ç´¢éœ€è¦embeddingå®¢æˆ·ç«¯")

        # è·å–å‘é‡å­—æ®µå
        vector_field = self.embedding_config.get("field_name", "embedding")

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        if self.debug:
            self.logger.debug(f"ğŸ”¢ æ­£åœ¨ç”Ÿæˆå‘é‡æ£€ç´¢æŸ¥è¯¢å‘é‡: '{query}'")

        query_embedding = self.embedding_client.embed_text(query)

        if self.debug:
            self.logger.debug(
                f"âœ… å‘é‡æ£€ç´¢æŸ¥è¯¢å‘é‡ç”Ÿæˆå®Œæˆï¼Œç»´åº¦: {len(query_embedding)}"
            )

        # å‘é‡æ£€ç´¢
        vector_search_body = {
            "knn": {
                "field": vector_field,
                "query_vector": query_embedding,
                "k": top_k,
                "num_candidates": top_k * 4,
            },
            "size": top_k,
        }

        if self.debug:
            self.logger.debug(f"ğŸ¯ å‘é‡æ£€ç´¢æŸ¥è¯¢ä½“: {vector_search_body}")

        response = self.client.search(index=self.index_name, body=vector_search_body)
        return self._format_results_with_highlights(response, query, "å‘é‡æ£€ç´¢")

    def _text_search_with_filter(
        self, query: str, top_k: int, filter_clause: Dict
    ) -> List[Dict[str, Any]]:
        """å¸¦è¿‡æ»¤å™¨çš„æ–‡æœ¬æ£€ç´¢"""
        # åŠ¨æ€æ„å»ºæŸ¥è¯¢å­—æ®µ
        should_queries = []

        for field, boost in self.search_fields.items():
            should_queries.append(
                {
                    "match": {
                        field: {
                            "query": query,
                            "boost": boost,
                            "analyzer": self.search_analyzer,
                        }
                    }
                }
            )

        # ä½¿ç”¨åŠ¨æ€é«˜äº®å­—æ®µæ„å»ºæ–¹æ³•
        highlight_fields = self._build_highlight_fields()

        search_body = {
            "query": {"bool": {"should": should_queries, "filter": filter_clause}},
            "highlight": {
                "fields": highlight_fields,
                "require_field_match": self.highlight_config.get(
                    "require_field_match", False
                ),
            },
            "size": top_k,
        }

        if self.debug:
            self.logger.debug(f"ğŸ“ å¸¦è¿‡æ»¤å™¨çš„æ–‡æœ¬æ£€ç´¢æŸ¥è¯¢ä½“: {search_body}")

        response = self.client.search(index=self.index_name, body=search_body)
        return self._format_results_with_highlights(response, query, "æ–‡æœ¬æ£€ç´¢")

    def _detect_chunk_level_config(self) -> Optional[Dict[str, Any]]:
        """åŠ¨æ€æ£€æµ‹chunk_levelé…ç½®"""
        try:
            # æ£€æµ‹å­—æ®µè·¯å¾„
            possible_paths = ["chunk_level", "metadata.chunk_level"]

            for path in possible_paths:
                test_query = {"query": {"exists": {"field": path}}, "size": 1}

                result = self.client.search(index=self.index_name, body=test_query)
                if result["hits"]["total"]["value"] > 0:
                    # è·å–è¯¥å­—æ®µçš„æ‰€æœ‰å€¼
                    agg_query = {
                        "size": 0,
                        "aggs": {"levels": {"terms": {"field": path, "size": 10}}},
                    }

                    agg_result = self.client.search(
                        index=self.index_name, body=agg_query
                    )
                    levels = [
                        bucket["key"]
                        for bucket in agg_result["aggregations"]["levels"]["buckets"]
                    ]

                    if levels:
                        # é€‰æ‹©æœ€å¤§çš„levelä½œä¸ºsmall chunk level
                        small_chunk_level = max(levels)

                        return {
                            "field_path": path,
                            "small_chunk_level": small_chunk_level,
                            "available_levels": levels,
                        }

            return None

        except Exception as e:
            if self.debug:
                self.logger.error(f"æ£€æµ‹chunk_levelé…ç½®å¤±è´¥: {e}")
            return None

    def _vector_search_with_filter(
        self, query: str, top_k: int, filter_clause: Dict
    ) -> List[Dict[str, Any]]:
        """å¸¦è¿‡æ»¤å™¨çš„å‘é‡æ£€ç´¢"""
        if not self.embedding_client:
            raise RuntimeError("å‘é‡æ£€ç´¢éœ€è¦embeddingå®¢æˆ·ç«¯")

        # è·å–å‘é‡å­—æ®µå
        vector_field = self.embedding_config.get("field_name", "embedding")

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        if self.debug:
            self.logger.debug(f"ğŸ”¢ æ­£åœ¨ç”Ÿæˆå‘é‡æ£€ç´¢æŸ¥è¯¢å‘é‡: '{query}'")

        query_embedding = self.embedding_client.embed_text(query)

        if self.debug:
            self.logger.debug(
                f"âœ… å‘é‡æ£€ç´¢æŸ¥è¯¢å‘é‡ç”Ÿæˆå®Œæˆï¼Œç»´åº¦: {len(query_embedding)}"
            )

        # å‘é‡æ£€ç´¢
        vector_search_body = {
            "knn": {
                "field": vector_field,
                "query_vector": query_embedding,
                "k": top_k,
                "num_candidates": top_k * 4,
                "filter": filter_clause,
            },
            "size": top_k,
        }

        if self.debug:
            self.logger.debug(f"ğŸ¯ å¸¦è¿‡æ»¤å™¨çš„å‘é‡æ£€ç´¢æŸ¥è¯¢ä½“: {vector_search_body}")

        response = self.client.search(index=self.index_name, body=vector_search_body)
        return self._format_results_with_highlights(response, query, "å‘é‡æ£€ç´¢")

    def _format_results_with_highlights(
        self, response, query: str = "", search_type: str = ""
    ) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æœå¹¶æ˜¾ç¤ºå‘½ä¸­è¯æ±‡"""
        results = []
        total_hits = response["hits"]["total"]

        if self.debug:
            if isinstance(total_hits, dict):
                total_count = total_hits.get("value", 0)
            else:
                total_count = total_hits
            self.logger.debug(
                f"ğŸ“Š {search_type} åŸå§‹æ£€ç´¢ç»“æœç»Ÿè®¡ - æ€»å‘½ä¸­æ•°: {total_count}, è¿”å›æ–‡æ¡£æ•°: {len(response['hits']['hits'])}"
            )

        for i, hit in enumerate(response["hits"]["hits"]):
            # æå–é«˜äº®ä¿¡æ¯
            highlights = hit.get("highlight", {})
            matched_terms = self._extract_matched_terms(highlights, query)

            result = {
                "id": hit["_id"],
                "score": hit["_score"],
                "content": hit["_source"].get("content", ""),
                "metadata": hit["_source"].get("metadata", {}),
                "recall_source": "text" if search_type == "æ–‡æœ¬æ£€ç´¢" else "vector",
                "highlights": matched_terms,  # æ·»åŠ é«˜äº®ä¿¡æ¯åˆ°ç»“æœä¸­
            }

            # è¿‡æ»¤ä½åˆ†ç»“æœ - é’ˆå¯¹ä¸åŒæ£€ç´¢ç±»å‹ä½¿ç”¨ä¸åŒé˜ˆå€¼
            if search_type == "æ–‡æœ¬æ£€ç´¢":
                # BM25æ–‡æœ¬æ£€ç´¢ä½¿ç”¨BM25åˆ†æ•°é˜ˆå€¼
                threshold = self.bm25_score_threshold
            else:
                # å‘é‡æ£€ç´¢ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼
                threshold = self.vector_similarity_threshold

            if result["score"] >= threshold:
                results.append(result)

                if self.debug:
                    # æ‰“å°è¯¦ç»†çš„å‘½ä¸­æ–‡æ¡£ä¿¡æ¯
                    content_preview = (
                        result["content"][:200] + "..."
                        if len(result["content"]) > 200
                        else result["content"]
                    )
                    metadata_info = (
                        ", ".join([f"{k}: {v}" for k, v in result["metadata"].items()])
                        if result["metadata"]
                        else "æ— å…ƒæ•°æ®"
                    )
                    recall_icon = "ğŸ“" if result["recall_source"] == "text" else "ğŸ¯"

                    self.logger.debug(
                        f"ğŸ“„ {recall_icon} {result['recall_source'].upper()}å¬å›æ–‡æ¡£ #{i+1}:"
                    )
                    self.logger.debug(f"   ğŸ“‹ æ–‡æ¡£ID: {result['id']}")
                    self.logger.debug(f"   â­ ç›¸ä¼¼åº¦åˆ†æ•°: {result['score']:.4f}")

                    # æ˜¾ç¤ºå‘½ä¸­çš„è¯æ±‡å’Œå­—æ®µ
                    if matched_terms:
                        self.logger.debug("   ğŸ¯ å‘½ä¸­è¯æ±‡è¯¦æƒ…:")
                        for field, terms in matched_terms.items():
                            if terms and isinstance(terms, dict):
                                # ä¼˜å…ˆæ˜¾ç¤ºç›¸å…³è¯æ±‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºæ‰€æœ‰è¯æ±‡
                                relevant_terms = terms.get("relevant_terms", [])
                                all_terms = terms.get("all_terms", [])
                                display_terms = (
                                    relevant_terms if relevant_terms else all_terms
                                )
                                if display_terms:
                                    self.logger.debug(
                                        f"      ğŸ“ {field}: {', '.join(display_terms)}"
                                    )
                            elif isinstance(terms, list) and terms:
                                # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¦‚æœæ˜¯åˆ—è¡¨ï¼‰
                                self.logger.debug(
                                    f"      ğŸ“ {field}: {', '.join(terms)}"
                                )

                        # æ˜¾ç¤ºé«˜äº®ç‰‡æ®µ
                        if highlights:
                            self.logger.debug("   ğŸ’¡ é«˜äº®ç‰‡æ®µ:")
                            for field, fragments in highlights.items():
                                if fragments:
                                    for j, fragment in enumerate(
                                        fragments[:2], 1
                                    ):  # æœ€å¤šæ˜¾ç¤º2ä¸ªç‰‡æ®µ
                                        clean_fragment = fragment.replace(
                                            "<mark>", "ã€"
                                        ).replace("</mark>", "ã€‘")
                                        self.logger.debug(
                                            f"      {j}. {field}: {clean_fragment}"
                                        )
                    else:
                        self.logger.debug("   â“ æœªæ‰¾åˆ°å…·ä½“å‘½ä¸­è¯æ±‡ï¼ˆå¯èƒ½æ˜¯æ¨¡ç³ŠåŒ¹é…ï¼‰")

                    self.logger.debug(f"   ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}")
                    self.logger.debug(f"   ğŸ·ï¸  å…ƒæ•°æ®: {metadata_info}")
                    self.logger.debug(f"   ğŸ“ å†…å®¹é•¿åº¦: {len(result['content'])} å­—ç¬¦")
            else:
                if self.debug:
                    self.logger.debug(
                        f"âŒ æ–‡æ¡£ {hit['_id']} åˆ†æ•° {hit['_score']:.4f} ä½äºé˜ˆå€¼ {self.similarity_threshold}ï¼Œå·²è¿‡æ»¤"
                    )

        if self.debug:
            self.logger.debug(
                f"ğŸ¯ {search_type} æœ€ç»ˆè¿”å› {len(results)} ä¸ªæœ‰æ•ˆç»“æœ (æŸ¥è¯¢: '{query}')"
            )
            if results:
                avg_score = sum(r["score"] for r in results) / len(results)
                max_score = max(r["score"] for r in results)
                min_score = min(r["score"] for r in results)
                self.logger.debug(
                    f"ğŸ“ˆ åˆ†æ•°ç»Ÿè®¡ - æœ€é«˜: {max_score:.4f}, æœ€ä½: {min_score:.4f}, å¹³å‡: {avg_score:.4f}"
                )

        return results

    def _extract_matched_terms(self, highlights: dict, query: str) -> dict:
        """ä»é«˜äº®ä¿¡æ¯ä¸­æå–åŒ¹é…çš„è¯æ±‡"""
        matched_terms = {}

        # åˆ†ææŸ¥è¯¢è¯
        query_terms = set(query.lower().split())

        for field, fragments in highlights.items():
            field_terms = set()
            relevant_terms = set()  # ä¸æŸ¥è¯¢ç›¸å…³çš„è¯æ±‡

            for fragment in fragments:
                # æå–è¢«æ ‡è®°çš„è¯æ±‡
                import re

                marked_words = re.findall(r"<mark>(.*?)</mark>", fragment)
                for word in marked_words:
                    # æ¸…ç†å’Œæ ‡å‡†åŒ–è¯æ±‡
                    clean_word = re.sub(r"[^\w\u4e00-\u9fff]", "", word.lower())
                    if clean_word:
                        field_terms.add(clean_word)
                        # æ£€æŸ¥æ˜¯å¦ä¸æŸ¥è¯¢è¯ç›¸å…³ï¼ˆå®Œå…¨åŒ¹é…æˆ–åŒ…å«å…³ç³»ï¼‰
                        if any(
                            clean_word in qterm or qterm in clean_word
                            for qterm in query_terms
                        ):
                            relevant_terms.add(clean_word)

            if field_terms:
                matched_terms[field] = {
                    "all_terms": list(field_terms),
                    "relevant_terms": list(relevant_terms),
                }

        return matched_terms

    def _hybrid_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æ··åˆæ£€ç´¢ï¼ˆæ–‡æœ¬+å‘é‡ï¼‰- æ”¯æŒRRFå’ŒåŠ æƒèåˆ"""
        if not self.embedding_client:
            raise RuntimeError("æ··åˆæ£€ç´¢éœ€è¦embeddingå®¢æˆ·ç«¯")

        # è·å–å‘é‡å­—æ®µå
        vector_field = self.embedding_config.get("field_name", "embedding")

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        if self.debug:
            self.logger.debug(f"ğŸ”¢ æ­£åœ¨ç”Ÿæˆæ··åˆæ£€ç´¢æŸ¥è¯¢å‘é‡: '{query}'")

        query_embedding = self.embedding_client.embed_text(query)

        if self.debug:
            self.logger.debug(
                f"âœ… æ··åˆæ£€ç´¢æŸ¥è¯¢å‘é‡ç”Ÿæˆå®Œæˆï¼Œç»´åº¦: {len(query_embedding)}"
            )
            self.logger.debug(f"ğŸ” å¼€å§‹æ‰§è¡Œæ··åˆæ£€ç´¢ - èåˆæ–¹æ³•: {self.fusion_method}")

        # 1. æ–‡æœ¬æ£€ç´¢ï¼ˆå¸¦é«˜äº®ï¼‰
        should_queries = []
        highlight_fields = {}

        for field, boost in self.search_fields.items():
            # å¯¹äºæ··åˆæ£€ç´¢ï¼Œé€‚å½“é™ä½æ–‡æœ¬æ£€ç´¢çš„æƒé‡
            adjusted_boost = boost * 0.8  # é™ä½20%æƒé‡ç»™å‘é‡æ£€ç´¢ç•™ç©ºé—´
            should_queries.append(
                {
                    "match": {
                        field: {
                            "query": query,
                            "boost": adjusted_boost,
                            "analyzer": self.search_analyzer,
                        }
                    }
                }
            )

            # ä¸ºæ‰€æœ‰æŸ¥è¯¢å­—æ®µæ·»åŠ é«˜äº®ï¼ˆä¹‹å‰åªä¸ºéƒ¨åˆ†å­—æ®µæ·»åŠ ï¼‰
            if field in ["content", "content_jieba"]:
                highlight_fields[field] = {
                    "fragment_size": 150,
                    "number_of_fragments": 2,
                    "pre_tags": ["<mark>"],
                    "post_tags": ["</mark>"],
                }
            elif "title" in field or "file_path" in field:
                highlight_fields[field] = {
                    "fragment_size": 100,
                    "number_of_fragments": 1,
                    "pre_tags": ["<mark>"],
                    "post_tags": ["</mark>"],
                }
            else:
                # ä¸ºå…¶ä»–æ‰€æœ‰å­—æ®µä¹Ÿæ·»åŠ é«˜äº®è®¾ç½®
                highlight_fields[field] = {
                    "fragment_size": 100,
                    "number_of_fragments": 1,
                    "pre_tags": ["<mark>"],
                    "post_tags": ["</mark>"],
                }

        text_search_body = {
            "query": {"bool": {"should": should_queries, "minimum_should_match": 1}},
            "highlight": {"fields": highlight_fields},
            "size": top_k * 2,
        }

        if self.debug:
            self.logger.debug(f"ğŸ“ æ··åˆæ£€ç´¢-æ–‡æœ¬éƒ¨åˆ†æŸ¥è¯¢ä½“: {text_search_body}")

        text_response = self.client.search(index=self.index_name, body=text_search_body)

        # 2. å‘é‡æ£€ç´¢
        vector_search_body = {
            "knn": {
                "field": vector_field,
                "query_vector": query_embedding,
                "k": top_k * 2,
                "num_candidates": top_k * 4,
            },
            "size": top_k * 2,
        }

        if self.debug:
            self.logger.debug(f"ğŸ¯ æ··åˆæ£€ç´¢-å‘é‡éƒ¨åˆ†æŸ¥è¯¢ä½“: {vector_search_body}")

        vector_response = self.client.search(
            index=self.index_name, body=vector_search_body
        )

        # æ ¹æ®èåˆæ–¹æ³•é€‰æ‹©åˆå¹¶ç­–ç•¥
        if self.fusion_method == "rrf":
            return self._merge_hybrid_results_with_rrf(
                text_response, vector_response, query, top_k
            )
        else:
            return self._merge_hybrid_results_with_highlights(
                text_response, vector_response, query, top_k
            )

    def _merge_hybrid_results_with_rrf(
        self, text_response, vector_response, query: str, top_k: int
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨RRFç®—æ³•åˆå¹¶æ··åˆæ£€ç´¢ç»“æœ"""
        if self.debug:
            text_hits = len(text_response["hits"]["hits"])
            vector_hits = len(vector_response["hits"]["hits"])
            self.logger.debug(
                f"ğŸ”„ å¼€å§‹RRFåˆå¹¶æ··åˆæ£€ç´¢ç»“æœ - æ–‡æœ¬æ£€ç´¢: {text_hits}ä¸ª, å‘é‡æ£€ç´¢: {vector_hits}ä¸ª, RRF-K: {self.rrf_k}"
            )

        # æ„å»ºæ–‡æ¡£æ˜ å°„å’Œæ’å
        text_docs = {}
        vector_docs = {}
        text_ranks = {}
        vector_ranks = {}
        highlights_map = {}

        # å¤„ç†æ–‡æœ¬æ£€ç´¢ç»“æœ
        for rank, hit in enumerate(text_response["hits"]["hits"], 1):
            doc_id = hit["_id"]
            text_docs[doc_id] = {
                "id": doc_id,
                "content": hit["_source"].get("content", ""),
                "metadata": hit["_source"].get("metadata", {}),
                "text_score": hit["_score"],
                "text_rank": rank,
            }
            text_ranks[doc_id] = rank
            highlights_map[doc_id] = hit.get("highlight", {})

            if self.debug:
                matched_terms = self._extract_matched_terms(
                    highlights_map[doc_id], query
                )
                terms_info = []
                for field, terms in matched_terms.items():
                    if terms and isinstance(terms, dict):
                        relevant_terms = terms.get("relevant_terms", [])
                        all_terms = terms.get("all_terms", [])
                        # ä¼˜å…ˆæ˜¾ç¤ºç›¸å…³è¯æ±‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºæ‰€æœ‰é«˜äº®è¯æ±‡
                        display_terms = relevant_terms if relevant_terms else all_terms
                        if display_terms:
                            terms_info.append(f"{field}: {', '.join(display_terms)}")
                    elif terms and isinstance(terms, list):
                        terms_info.append(f"{field}: {', '.join(terms)}")

                final_terms_info = ", ".join(terms_info) if terms_info else "æ— "
                # æ·»åŠ é«˜äº®ä¿¡æ¯è°ƒè¯•
                highlight_info = highlights_map[doc_id]
                self.logger.debug(f"ğŸ” æ–‡æ¡£ {doc_id} çš„é«˜äº®ä¿¡æ¯: {highlight_info}")

                matched_terms = self._extract_matched_terms(
                    highlights_map[doc_id], query
                )
                self.logger.debug(f"ğŸ¯ æ–‡æ¡£ {doc_id} æå–çš„åŒ¹é…è¯: {matched_terms}")

                terms_info = []
                for field, terms in matched_terms.items():
                    if terms and isinstance(terms, dict):
                        relevant_terms = terms.get("relevant_terms", [])
                        all_terms = terms.get("all_terms", [])
                        # ä¼˜å…ˆæ˜¾ç¤ºç›¸å…³è¯æ±‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºæ‰€æœ‰é«˜äº®è¯æ±‡
                        display_terms = relevant_terms if relevant_terms else all_terms
                        self.logger.debug(
                            f"ğŸ“‹ å­—æ®µ {field}: relevant_terms={relevant_terms}, all_terms={all_terms}, display_terms={display_terms}"
                        )
                        if display_terms:
                            terms_info.append(f"{field}: {', '.join(display_terms)}")
                    elif terms and isinstance(terms, list):
                        terms_info.append(f"{field}: {', '.join(terms)}")

                final_terms_info = ", ".join(terms_info) if terms_info else "æ— "
                self.logger.debug(
                    f"ğŸ“ æ–‡æœ¬å¬å›æ–‡æ¡£: {doc_id}, æ’å: {rank}, åˆ†æ•°: {hit['_score']:.4f}, å‘½ä¸­è¯: {final_terms_info}"
                )

        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        for rank, hit in enumerate(vector_response["hits"]["hits"], 1):
            doc_id = hit["_id"]
            vector_docs[doc_id] = {
                "id": doc_id,
                "content": hit["_source"].get("content", ""),
                "metadata": hit["_source"].get("metadata", {}),
                "vector_score": hit["_score"],
                "vector_rank": rank,
            }
            vector_ranks[doc_id] = rank

            if self.debug:
                self.logger.debug(
                    f"ğŸ¯ å‘é‡å¬å›æ–‡æ¡£: {doc_id}, æ’å: {rank}, åˆ†æ•°: {hit['_score']:.4f}"
                )

        # è®¡ç®—RRFåˆ†æ•°
        all_doc_ids = set(text_ranks.keys()) | set(vector_ranks.keys())
        rrf_results = []

        for doc_id in all_doc_ids:
            text_rank = text_ranks.get(doc_id, float("inf"))
            vector_rank = vector_ranks.get(doc_id, float("inf"))

            # è®¡ç®—RRFåˆ†æ•°
            rrf_score = 0
            if text_rank != float("inf"):
                rrf_score += 1 / (self.rrf_k + text_rank)
            if vector_rank != float("inf"):
                rrf_score += 1 / (self.rrf_k + vector_rank)

            # ç¡®å®šå¬å›æ¥æº
            if text_rank != float("inf") and vector_rank != float("inf"):
                recall_source = "hybrid"
                doc_info = {**text_docs[doc_id], **vector_docs[doc_id]}
            elif text_rank != float("inf"):
                recall_source = "text"
                doc_info = {
                    **text_docs[doc_id],
                    "vector_score": 0.0,
                    "vector_rank": None,
                }
            else:
                recall_source = "vector"
                doc_info = {**vector_docs[doc_id], "text_score": 0.0, "text_rank": None}
                highlights_map[doc_id] = {}  # å‘é‡æ£€ç´¢æ²¡æœ‰é«˜äº®

            result = {
                "id": doc_id,
                "score": rrf_score,  # ä½¿ç”¨RRFåˆ†æ•°ä½œä¸ºæœ€ç»ˆåˆ†æ•°
                "content": doc_info["content"],
                "metadata": doc_info["metadata"],
                "recall_source": recall_source,
                "text_score": doc_info.get("text_score", 0.0),
                "vector_score": doc_info.get("vector_score", 0.0),
                "text_rank": doc_info.get("text_rank"),
                "vector_rank": doc_info.get("vector_rank"),
                "rrf_score": rrf_score,
                "highlights": self._extract_matched_terms(
                    highlights_map.get(doc_id, {}), query
                ),
            }

            rrf_results.append(result)

        # æŒ‰RRFåˆ†æ•°æ’åº
        rrf_results.sort(key=lambda x: x["rrf_score"], reverse=True)

        # å–top_kå¹¶åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        final_results = []
        for i, result in enumerate(rrf_results[:top_k]):
            if self.debug:
                self.logger.debug(
                    f"ğŸ” æ£€æŸ¥RRFæ’å#{i+1} æ–‡æ¡£ {result['id']}: RRFåˆ†æ•°={result['rrf_score']:.6f}"
                )

            # å¯¹äºRRFï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ç­–ç•¥
            if result["rrf_score"] > 0:  # RRFåˆ†æ•°å¤§äº0å³è¡¨ç¤ºæœ‰æ„ä¹‰
                final_results.append(result)
                if self.debug:
                    self.logger.debug(
                        f"âœ… æ–‡æ¡£ {result['id']} é€šè¿‡RRFè¿‡æ»¤ï¼ŒåŠ å…¥æœ€ç»ˆç»“æœ"
                    )
            else:
                if self.debug:
                    self.logger.debug(
                        f"âŒ æ–‡æ¡£ {result['id']} RRFåˆ†æ•°={result['rrf_score']:.6f} <= 0ï¼Œè¢«è¿‡æ»¤"
                    )

        if self.debug:
            self.logger.debug("ğŸ“Š RRFæ··åˆæ£€ç´¢ç»“æœç»Ÿè®¡:")
            text_only = sum(1 for r in final_results if r["recall_source"] == "text")
            vector_only = sum(
                1 for r in final_results if r["recall_source"] == "vector"
            )
            hybrid_both = sum(
                1 for r in final_results if r["recall_source"] == "hybrid"
            )

            self.logger.debug(f"   ğŸ“ ä»…æ–‡æœ¬å¬å›: {text_only}ä¸ª")
            self.logger.debug(f"   ğŸ¯ ä»…å‘é‡å¬å›: {vector_only}ä¸ª")
            self.logger.debug(f"   ğŸ”„ æ··åˆå¬å›(æ–‡æœ¬+å‘é‡): {hybrid_both}ä¸ª")
            self.logger.debug(f"   ğŸ¯ æœ€ç»ˆè¿”å›: {len(final_results)}ä¸ªæ–‡æ¡£")

            # è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„RRFä¿¡æ¯
            for i, result in enumerate(final_results, 1):
                content_preview = (
                    result["content"][:100] + "..."
                    if len(result["content"]) > 100
                    else result["content"]
                )

                self.logger.debug(f"ğŸ“„ RRFæ’å#{i} - æ–‡æ¡£ID: {result['id']}")

                # æ˜¾ç¤ºRRFè®¡ç®—è¯¦æƒ…
                rrf_detail = f"RRFåˆ†æ•°: {result['rrf_score']:.6f}"
                if result["text_rank"] and result["vector_rank"]:
                    rrf_detail += f" (æ–‡æœ¬æ’å: {result['text_rank']}, å‘é‡æ’å: {result['vector_rank']})"
                elif result["text_rank"]:
                    rrf_detail += f" (ä»…æ–‡æœ¬æ’å: {result['text_rank']})"
                else:
                    rrf_detail += f" (ä»…å‘é‡æ’å: {result['vector_rank']})"

                self.logger.debug(f"   ğŸ”¢ {rrf_detail}")

                # æ˜¾ç¤ºåŸå§‹åˆ†æ•°
                if result["text_score"] > 0 and result["vector_score"] > 0:
                    self.logger.debug(
                        f"   ğŸ“Š åŸå§‹åˆ†æ•° - æ–‡æœ¬: {result['text_score']:.4f}, å‘é‡: {result['vector_score']:.4f}"
                    )
                elif result["text_score"] > 0:
                    self.logger.debug(
                        f"   ğŸ“Š åŸå§‹åˆ†æ•° - æ–‡æœ¬: {result['text_score']:.4f}"
                    )
                else:
                    self.logger.debug(
                        f"   ğŸ“Š åŸå§‹åˆ†æ•° - å‘é‡: {result['vector_score']:.4f}"
                    )

                # æ˜¾ç¤ºå‘½ä¸­è¯æ±‡ï¼ˆä»…æ–‡æœ¬å¬å›æœ‰ï¼‰
                if (
                    result["recall_source"] in ["text", "hybrid"]
                    and result["highlights"]
                ):
                    terms_info = []
                    for field, terms in result["highlights"].items():
                        if terms and isinstance(terms, dict):
                            relevant_terms = terms.get("relevant_terms", [])
                            if relevant_terms:  # åªæœ‰å½“æœ‰ç›¸å…³è¯æ±‡æ—¶æ‰æ·»åŠ 
                                terms_info.append(
                                    f"{field}: {', '.join(relevant_terms)}"
                                )
                        elif terms and isinstance(terms, list):
                            terms_info.append(f"{field}: {', '.join(terms)}")

                    if terms_info:
                        self.logger.debug(f"   ğŸ¯ å‘½ä¸­è¯æ±‡: {', '.join(terms_info)}")

                self.logger.debug(f"   ğŸ·ï¸  å¬å›æ–¹å¼: {result['recall_source']}")
                self.logger.debug(f"   ğŸ“ å†…å®¹: {content_preview}")

        return final_results

    def _merge_hybrid_results_with_highlights(self, text_response, vector_response, query: str, top_k: int) -> List[Dict[str, Any]]:
        """åˆå¹¶æ··åˆæ£€ç´¢ç»“æœå¹¶æ ‡è®°æ¥æºï¼ˆåŒ…å«é«˜äº®ä¿¡æ¯ï¼‰- åŠ æƒèåˆæ–¹æ³•"""

    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¾“å…¥æ•°æ® - æ”¯æŒå¤šæŸ¥è¯¢æ£€ç´¢"""
        if "query" not in data:
            raise ValueError("è¾“å…¥æ•°æ®å¿…é¡»åŒ…å« 'query' å­—æ®µ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰©å±•æŸ¥è¯¢
        expanded_queries = data.get("expanded_queries", [])
        original_query = data["query"]
        top_k = data.get("top_k", self.top_k)
        
        if expanded_queries and len(expanded_queries) > 1:
            # å¤šæŸ¥è¯¢æ£€ç´¢
            if self.debug:
                self.logger.info(f"ğŸ” æ‰§è¡Œå¤šæŸ¥è¯¢æ£€ç´¢ï¼Œå…± {len(expanded_queries)} ä¸ªæŸ¥è¯¢")
                for i, q in enumerate(expanded_queries, 1):
                    self.logger.info(f"   æŸ¥è¯¢ {i}: {q}")
            
            all_results = []
            for i, query in enumerate(expanded_queries):
                if self.debug:
                    self.logger.info(f"ğŸ” æ‰§è¡Œç¬¬ {i+1} ä¸ªæŸ¥è¯¢: {query}")
                
                results = self.retrieve(query, top_k)
                
                # ä¸ºæ¯ä¸ªç»“æœæ·»åŠ æŸ¥è¯¢æ¥æºä¿¡æ¯
                for result in results:
                    result['query_source'] = f"query_{i+1}"
                    result['source_query'] = query
                
                all_results.extend(results)
                
                if self.debug:
                    self.logger.info(f"   âœ… æŸ¥è¯¢ {i+1} è¿”å› {len(results)} ä¸ªç»“æœ")
            
            # å»é‡å’Œé‡æ’åº
            unique_results = self._deduplicate_and_merge_results(all_results, top_k)
            
            if self.debug:
                self.logger.info(f"ğŸ¯ å¤šæŸ¥è¯¢æ£€ç´¢å®Œæˆï¼Œå»é‡åè¿”å› {len(unique_results)} ä¸ªç»“æœ")
            
            return {
                "documents": unique_results,
                "query": original_query,
                "expanded_queries": expanded_queries,
                "result_count": len(unique_results),
                "metadata": {
                    "component": self.name,
                    "retriever_type": self.__class__.__name__,
                    "top_k": top_k,
                    "multi_query": True,
                    "num_queries": len(expanded_queries),
                },
            }
        else:
            # å•æŸ¥è¯¢æ£€ç´¢ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            results = self.retrieve(original_query, top_k)
            
            return {
                "documents": results,
                "query": original_query,
                "result_count": len(results),
                "metadata": {
                    "component": self.name,
                    "retriever_type": self.__class__.__name__,
                    "top_k": top_k,
                    "multi_query": False,
                },
            }
    
    def _deduplicate_and_merge_results(self, all_results: List[Dict[str, Any]], top_k: int) -> List[Dict[str, Any]]:
        """å»é‡å¹¶åˆå¹¶å¤šæŸ¥è¯¢ç»“æœ"""
        seen_ids = set()
        unique_results = []
        
        # æŒ‰åˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        for result in all_results:
            doc_id = result.get('id')
            if doc_id not in seen_ids:
                seen_ids.add(doc_id)
                unique_results.append(result)
                
                if len(unique_results) >= top_k:
                    break
        
        return unique_results

    def _merge_hybrid_results_with_highlights(self, text_response, vector_response, query: str, top_k: int) -> List[Dict[str, Any]]:
        """åˆå¹¶æ··åˆæ£€ç´¢ç»“æœå¹¶æ ‡è®°æ¥æºï¼ˆåŒ…å«é«˜äº®ä¿¡æ¯ï¼‰- åŠ æƒèåˆæ–¹æ³•"""
        results_map = {}
        highlights_map = {}  # å­˜å‚¨é«˜äº®ä¿¡æ¯

        if self.debug:
            text_hits = len(text_response["hits"]["hits"])
            vector_hits = len(vector_response["hits"]["hits"])
            self.logger.debug(
                f"ğŸ”„ å¼€å§‹åŠ æƒåˆå¹¶æ··åˆæ£€ç´¢ç»“æœ - æ–‡æœ¬æ£€ç´¢: {text_hits}ä¸ª, å‘é‡æ£€ç´¢: {vector_hits}ä¸ª"
            )

        # å¤„ç†æ–‡æœ¬æ£€ç´¢ç»“æœ
        for hit in text_response["hits"]["hits"]:
            doc_id = hit["_id"]
            score = hit["_score"]
            highlights = hit.get("highlight", {})

            result = {
                "id": doc_id,
                "score": score,
                "content": hit["_source"].get("content", ""),
                "metadata": hit["_source"].get("metadata", {}),
                "recall_source": "text",
                "text_score": score,
                "vector_score": 0.0,
                "hybrid_score": score * self.text_weight,
            }

            results_map[doc_id] = result
            highlights_map[doc_id] = highlights

            if self.debug:
                matched_terms = self._extract_matched_terms(highlights, query)
                terms_info = ", ".join(
                    [
                        f"{field}: {', '.join(terms['relevant_terms']) if isinstance(terms, dict) else str(terms)}"
                        for field, terms in matched_terms.items()
                        if terms
                    ]
                )
                self.logger.debug(
                    f"ğŸ“ æ–‡æœ¬å¬å›æ–‡æ¡£: {doc_id}, åˆ†æ•°: {score:.4f}, å‘½ä¸­è¯: {terms_info or 'æ— '}"
                )

        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        for hit in vector_response["hits"]["hits"]:
            doc_id = hit["_id"]
            score = hit["_score"]

            if doc_id in results_map:
                # æ–‡æ¡£åŒæ—¶è¢«æ–‡æœ¬å’Œå‘é‡å¬å›
                results_map[doc_id]["recall_source"] = "hybrid"
                results_map[doc_id]["vector_score"] = score
                results_map[doc_id]["hybrid_score"] = (
                    results_map[doc_id]["text_score"] * self.text_weight
                    + score * self.vector_weight
                )

                if self.debug:
                    highlights = highlights_map.get(doc_id, {})
                    matched_terms = self._extract_matched_terms(highlights, query)
                    terms_info = ", ".join(
                        [
                            f"{field}: {', '.join(terms['relevant_terms']) if isinstance(terms, dict) else str(terms)}"
                            for field, terms in matched_terms.items()
                            if terms
                        ]
                    )
                    self.logger.debug(
                        f"ğŸ¯ æ··åˆå¬å›æ–‡æ¡£: {doc_id}, æ–‡æœ¬åˆ†æ•°: {results_map[doc_id]['text_score']:.4f}, å‘é‡åˆ†æ•°: {score:.4f}, æ··åˆåˆ†æ•°: {results_map[doc_id]['hybrid_score']:.4f}, å‘½ä¸­è¯: {terms_info or 'æ— '}"
                    )
            else:
                # ä»…è¢«å‘é‡å¬å›
                result = {
                    "id": doc_id,
                    "score": score,
                    "content": hit["_source"].get("content", ""),
                    "metadata": hit["_source"].get("metadata", {}),
                    "recall_source": "vector",
                    "text_score": 0.0,
                    "vector_score": score,
                    "hybrid_score": score * self.vector_weight,
                }

                results_map[doc_id] = result
                highlights_map[doc_id] = {}

                if self.debug:
                    self.logger.debug(f"ğŸ¯ å‘é‡å¬å›æ–‡æ¡£: {doc_id}, åˆ†æ•°: {score:.4f}")

        # å…ˆè¿›è¡Œç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ï¼Œå†æŒ‰æ··åˆåˆ†æ•°æ’åºå¹¶å–top_k
        filtered_results = []
        for result in results_map.values():
            result["score"] = result["hybrid_score"]
            # å¯¹äºæ··åˆæ£€ç´¢ï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ç­–ç•¥
            threshold = self.similarity_threshold * 0.8  # é™ä½20%é˜ˆå€¼
            if result["score"] >= threshold:
                filtered_results.append(result)

        # æŒ‰æ··åˆåˆ†æ•°æ’åºå¹¶å–top_k
        filtered_results.sort(key=lambda x: x["hybrid_score"], reverse=True)
        final_results = filtered_results[:top_k]

        if self.debug:
            self.logger.debug("ğŸ“Š åŠ æƒæ··åˆæ£€ç´¢ç»“æœç»Ÿè®¡:")
            text_only = sum(1 for r in final_results if r["recall_source"] == "text")
            vector_only = sum(
                1 for r in final_results if r["recall_source"] == "vector"
            )
            hybrid_both = sum(
                1 for r in final_results if r["recall_source"] == "hybrid"
            )

            self.logger.debug(f"   ğŸ“ ä»…æ–‡æœ¬å¬å›: {text_only}ä¸ª")
            self.logger.debug(f"   ğŸ¯ ä»…å‘é‡å¬å›: {vector_only}ä¸ª")
            self.logger.debug(f"   ğŸ”„ æ··åˆå¬å›(æ–‡æœ¬+å‘é‡): {hybrid_both}ä¸ª")
            self.logger.debug(f"   ğŸ¯ æœ€ç»ˆè¿”å›: {len(final_results)}ä¸ªæ–‡æ¡£")

            # è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„å¬å›ä¿¡æ¯
            for i, result in enumerate(final_results, 1):
                content_preview = (
                    result["content"][:100] + "..."
                    if len(result["content"]) > 100
                    else result["content"]
                )

                self.logger.debug(f"ğŸ“„ æ’å#{i} - æ–‡æ¡£ID: {result['id']}")

                # æ˜¾ç¤ºæ–‡æœ¬å¬å›çš„å‘½ä¸­è¯æ±‡
                if result["recall_source"] in ["text", "hybrid"]:
                    highlights = highlights_map.get(result["id"], {})
                    matched_terms = self._extract_matched_terms(highlights, query)
                    if matched_terms:
                        terms_info = ", ".join(
                            [
                                f"{field}: {', '.join(terms['relevant_terms']) if isinstance(terms, dict) else str(terms)}"
                                for field, terms in matched_terms.items()
                                if terms
                            ]
                        )
                        if terms_info:
                            self.logger.debug(f"   ğŸ¯ å‘½ä¸­è¯æ±‡: {terms_info}")

                source_info = f"å¬å›æ–¹å¼: {result['recall_source']}"
                if result["recall_source"] == "hybrid":
                    source_info += f" (æ–‡æœ¬: {result['text_score']:.4f}, å‘é‡: {result['vector_score']:.4f})"
                elif result["recall_source"] == "text":
                    source_info += f" (æ–‡æœ¬åˆ†æ•°: {result['text_score']:.4f})"
                else:
                    source_info += f" (å‘é‡åˆ†æ•°: {result['vector_score']:.4f})"

                self.logger.debug(f"   ğŸ·ï¸  {source_info}")
                self.logger.debug(f"   â­ æœ€ç»ˆåˆ†æ•°: {result['score']:.4f}")
                self.logger.debug(f"   ğŸ“ å†…å®¹: {content_preview}")

        return final_results
