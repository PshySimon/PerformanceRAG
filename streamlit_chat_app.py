#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºStreamlitçš„RAGå¯¹è¯åº”ç”¨
"""

import os
import sys
import time
from typing import Any, Dict, Generator, List

import streamlit as st

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rag.pipeline.factory import create_pipeline
from utils.logger import get_logger, setup_logging

# ==================== é…ç½®å’Œåˆå§‹åŒ– ====================

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è®¾ç½®æ—¥å¿—
setup_logging(level="DEBUG")
logger = get_logger(__name__)

# åˆå§‹åŒ–session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pipeline" not in st.session_state:
    st.session_state.pipeline = None
if "pipeline_ready" not in st.session_state:
    st.session_state.pipeline_ready = False

# ==================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================


@st.cache_resource
def init_pipeline():
    """åˆå§‹åŒ–pipelineï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    try:
        logger.info("åˆå§‹åŒ–ESæœç´¢Pipeline...")
        pipeline = create_pipeline("es_search_pipeline")
        logger.info("Pipelineåˆå§‹åŒ–å®Œæˆ")
        return pipeline, True
    except Exception as e:
        logger.error(f"Pipelineåˆå§‹åŒ–å¤±è´¥: {e}")
        return None, False


def search_with_pipeline(
    query: str, top_k: int, search_type: str, show_intermediate: bool = False
) -> Dict[str, Any]:
    """ä½¿ç”¨pipelineè¿›è¡Œæœç´¢"""
    try:
        if show_intermediate:
            result = st.session_state.pipeline.run_with_intermediate_results(
                {"query": query, "top_k": top_k, "search_type": search_type},
                entry_point="es_retriever",
            )
        else:
            result = st.session_state.pipeline.run(
                {"query": query, "top_k": top_k, "search_type": search_type},
                entry_point="es_retriever",
            )
        return result
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return {"error": str(e)}


def search_with_pipeline_stream(
    query: str, top_k: int, search_type: str
) -> Generator[Dict[str, Any], None, None]:
    """æµå¼æœç´¢å‡½æ•°ï¼Œæ”¯æŒçŠ¶æ€æ›´æ–°"""
    try:
        pipeline = st.session_state.pipeline
        if not pipeline:
            yield {"error": "Pipelineæœªåˆå§‹åŒ–"}
            return

        # 1. å¼€å§‹æ£€ç´¢é˜¶æ®µ
        yield {
            "current_step": "retrieval",
            "step_state": "running",
            "message": "æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...",
        }
        time.sleep(0.5)

        # æ‰§è¡Œå®é™…çš„pipeline
        result = pipeline.run(
            {"query": query, "top_k": top_k, "search_type": search_type},
            entry_point="es_retriever",
        )

        if "error" in result:
            yield {"error": result["error"]}
            return

        # 2. æ£€ç´¢å®Œæˆï¼Œå¼€å§‹é‡æ’
        yield {
            "current_step": "retrieval",
            "step_state": "completed",
            "message": "æ–‡æ¡£æ£€ç´¢å®Œæˆ",
        }
        yield {
            "current_step": "rerank",
            "step_state": "running",
            "message": "æ­£åœ¨é‡æ–°æ’åºæ–‡æ¡£...",
        }
        time.sleep(0.3)

        # 3. é‡æ’å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆ
        yield {
            "current_step": "rerank",
            "step_state": "completed",
            "message": "æ–‡æ¡£é‡æ’å®Œæˆ",
        }
        yield {
            "current_step": "generation",
            "step_state": "running",
            "message": "æ­£åœ¨ç”Ÿæˆå›ç­”...",
        }

        # 4. æ¨¡æ‹Ÿæµå¼ç”Ÿæˆ
        answer = result.get("answer", "")
        if answer:
            chunk_size = 10
            for i in range(0, len(answer), chunk_size):
                chunk = answer[i : i + chunk_size]
                partial_answer = answer[: i + len(chunk)]

                yield {
                    "answer_chunk": chunk,
                    "answer_partial": partial_answer,
                    "current_step": "generation",
                    "step_state": "running",
                }
                time.sleep(0.05)

        # 5. ç”Ÿæˆå®Œæˆ
        yield {
            "current_step": "generation",
            "step_state": "completed",
            "message": "å›ç­”ç”Ÿæˆå®Œæˆ",
        }
        yield {
            "current_step": "completion",
            "step_state": "completed",
            "message": "å¤„ç†å®Œæˆ",
        }

        # 6. è¿”å›æœ€ç»ˆç»“æœ
        yield {
            "is_final": True,
            "answer": answer,
            "documents": result.get("documents", []),
            "message": "æ‰€æœ‰å¤„ç†å®Œæˆ",
        }

    except Exception as e:
        logger.error(f"æµå¼æœç´¢å¤±è´¥: {e}")
        yield {"error": str(e)}


# ==================== UIç»„ä»¶å‡½æ•° ====================


def create_progress_indicator():
    """åˆ›å»ºç®€åŒ–çš„è¿›åº¦æŒ‡ç¤ºå™¨ - å•è¡Œæ˜¾ç¤ºå½“å‰æ‰§è¡Œç»„ä»¶"""
    # åˆ›å»ºå•ä¸ªå®¹å™¨ç”¨äºæ˜¾ç¤ºå½“å‰çŠ¶æ€
    status_container = st.empty()
    
    return {
        "status_container": status_container,
        "current_step": None
    }

def update_status(progress_dict: Dict[str, Any], step: str, status: str, message: str = ""):
    """æ›´æ–°è¿›åº¦çŠ¶æ€ - å•è¡Œæ˜¾ç¤º"""
    # çŠ¶æ€å›¾æ ‡æ˜ å°„
    status_icons = {
        "waiting": "â³",
        "running": "ğŸ”„",  # è½¬åœˆæ•ˆæœ
        "completed": "âœ…",
        "error": "âŒ"
    }
    
    # æ­¥éª¤åç§°æ˜ å°„
    step_names = {
        "retrieval": "æ–‡æ¡£æ£€ç´¢",
        "reranking": "ç»“æœé‡æ’", 
        "generation": "ç­”æ¡ˆç”Ÿæˆ"
    }
    
    # åªåœ¨çŠ¶æ€å˜åŒ–æ—¶æ›´æ–°æ˜¾ç¤º
    if progress_dict["current_step"] != step or status == "running":
        progress_dict["current_step"] = step
        
        icon = status_icons.get(status, "â³")
        step_name = step_names.get(step, step)
        
        # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
        if status == "running":
            display_text = f"{icon} æ­£åœ¨æ‰§è¡Œ: **{step_name}**"
            if message:
                display_text += f" - {message}"
        elif status == "completed":
            display_text = f"{icon} å·²å®Œæˆ: **{step_name}**"
        elif status == "error":
            display_text = f"{icon} æ‰§è¡Œå¤±è´¥: **{step_name}**"
            if message:
                display_text += f" - {message}"
        else:
            display_text = f"{icon} **{step_name}**"
        
        # æ›´æ–°æ˜¾ç¤º
        progress_dict["status_container"].markdown(display_text)


def render_sidebar() -> tuple:
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # æœç´¢å‚æ•°
        search_type = st.selectbox(
            "æœç´¢ç±»å‹",
            ["hybrid", "text", "vector"],
            index=0,
            help="é€‰æ‹©æœç´¢æ–¹å¼ï¼šhybrid(æ··åˆ)ã€text(æ–‡æœ¬)ã€vector(å‘é‡)",
        )

        top_k = st.slider(
            "æ£€ç´¢æ–‡æ¡£æ•°é‡",
            min_value=1,
            max_value=10,
            value=3,
            help="æ£€ç´¢çš„ç›¸å…³æ–‡æ¡£æ•°é‡",
        )

        st.divider()

        # è¾“å‡ºæ¨¡å¼é…ç½®
        st.header("ğŸ’¬ è¾“å‡ºæ¨¡å¼")
        output_mode = st.radio(
            "é€‰æ‹©è¾“å‡ºæ–¹å¼",
            ["ğŸš€ æµå¼è¾“å‡º", "ğŸ“„ å®Œæ•´è¾“å‡º"],
            index=0,
            help="æµå¼è¾“å‡ºï¼šå®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹\nå®Œæ•´è¾“å‡ºï¼šç­‰å¾…å®Œæˆåä¸€æ¬¡æ€§æ˜¾ç¤º",
        )

        show_intermediate = st.checkbox(
            "æ˜¾ç¤ºæ‰§è¡Œè¿‡ç¨‹", value=True, help="æ˜¾ç¤ºå„ä¸ªç»„ä»¶çš„å¤„ç†è¿‡ç¨‹å’Œä¸­é—´ç»“æœ"
        )

        show_document_content = st.checkbox(
            "æ˜¾ç¤ºæ–‡æ¡£è¯¦æƒ…", value=False, help="æ˜¾ç¤ºæ£€ç´¢åˆ°çš„å®Œæ•´æ–‡æ¡£å†…å®¹"
        )

        # ç³»ç»ŸçŠ¶æ€
        st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        render_system_status()

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

    return search_type, top_k, output_mode, show_intermediate, show_document_content


def render_system_status() -> None:
    """æ¸²æŸ“ç³»ç»ŸçŠ¶æ€"""
    if not st.session_state.pipeline_ready:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
            pipeline, ready = init_pipeline()
            st.session_state.pipeline = pipeline
            st.session_state.pipeline_ready = ready

    if st.session_state.pipeline_ready:
        st.success("âœ… ç³»ç»Ÿå°±ç»ª")
        if st.session_state.pipeline:
            components = st.session_state.pipeline.list_components()
            st.info(f"ç»„ä»¶æ•°é‡: {len(components)}")
    else:
        st.error("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        st.stop()


def format_document_sources(documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ ¼å¼åŒ–æ–‡æ¡£æ¥æºä¿¡æ¯"""
    sources = []
    for doc in documents[:3]:
        title = (
            doc.get("metadata", {}).get("filename")
            or doc.get("metadata", {}).get("source", "").split("/")[-1]
            or f"æ–‡æ¡£-{doc.get('id', 'N/A')}"
        )
        
        # æå–å…³é”®è¯ä¿¡æ¯
        keywords = []
        if 'highlights' in doc:
            highlights = doc['highlights']
            for field, terms_info in highlights.items():
                if isinstance(terms_info, dict) and 'relevant_terms' in terms_info:
                    keywords.extend(terms_info['relevant_terms'])
        
        content = doc.get("content", "")[:200]
        if '<mark>' in content:
            content = content.replace('<mark>', '**').replace('</mark>', '**')
            
        source_info = {
            "title": title,
            "content": content + "...",
            "score": doc.get("score", 0),
            "recall_source": doc.get('recall_source', 'unknown'),
            "keywords": list(set(keywords)) if keywords else []
        }
        sources.append(source_info)
    return sources


def render_sources(sources: List[Dict[str, Any]]) -> None:
    """æ¸²æŸ“å‚è€ƒæ¥æº"""
    if sources:
        with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
            for i, source in enumerate(sources, 1):
                recall_icon = "ğŸ“" if source.get('recall_source') == "text" else "ğŸ¯" if source.get('recall_source') == "vector" else "ğŸ”„"
                
                st.markdown(
                    f"**{i}. {recall_icon} {source['title']}** (ç›¸ä¼¼åº¦: {source['score']:.2f})"
                )
                
                # æ˜¾ç¤ºå…³é”®è¯
                if source.get('keywords'):
                    st.markdown(f"ğŸ¯ **å…³é”®è¯**: {', '.join(source['keywords'])}")
                
                st.markdown(f"> {source['content']}")
                st.divider()


def render_chat_history() -> None:
    """æ¸²æŸ“å¯¹è¯å†å²"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # æ˜¾ç¤ºæ¥æºä¿¡æ¯
            if "sources" in message and message["sources"]:
                render_sources(message["sources"])


def handle_streaming_response(
    prompt: str, top_k: int, search_type: str
) -> None:
    """å¤„ç†æµå¼å“åº”"""
    # åœ¨èŠå¤©ç•Œé¢ä¸­é—´åˆ›å»ºè¿›åº¦æŒ‡ç¤ºå™¨ï¼ˆç‹¬ç«‹äºå›å¤æ¡†ï¼‰
    progress_placeholder = st.empty()
    
    # åˆ›å»ºåŠ©æ‰‹å›å¤æ¡†
    with st.chat_message("assistant"):
        # åˆ›å»ºå ä½ç¬¦
        answer_placeholder = st.empty()
        sources_placeholder = st.empty()
        
        try:
            # å¼€å§‹æœç´¢æµç¨‹
            progress_placeholder.markdown("ğŸ”„ æ­£åœ¨æ‰§è¡Œ: **æ–‡æ¡£æ£€ç´¢** - æœç´¢ç›¸å…³æ–‡æ¡£...")
            
            # æ‰§è¡Œæœç´¢
            result_generator = search_with_pipeline_stream(prompt, top_k, search_type)
            
            final_result = None
            current_answer = ""
            
            for result in result_generator:
                # æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„å¤„ç†ä¸åŒé˜¶æ®µ
                if result.get("current_step") == "retrieval":
                    if result.get("step_state") == "running":
                        progress_placeholder.markdown("ğŸ”„ æ­£åœ¨æ‰§è¡Œ: **æ–‡æ¡£æ£€ç´¢** - æœç´¢ç›¸å…³æ–‡æ¡£...")
                    elif result.get("step_state") == "completed":
                        progress_placeholder.markdown("âœ… å·²å®Œæˆ: **æ–‡æ¡£æ£€ç´¢**")
                        
                elif result.get("current_step") == "rerank":
                    if result.get("step_state") == "running":
                        progress_placeholder.markdown("ğŸ”„ æ­£åœ¨æ‰§è¡Œ: **ç»“æœé‡æ’** - é‡æ–°æ’åºæ–‡æ¡£...")
                    elif result.get("step_state") == "completed":
                        progress_placeholder.markdown("âœ… å·²å®Œæˆ: **ç»“æœé‡æ’**")
                        progress_placeholder.markdown("ğŸ”„ æ­£åœ¨æ‰§è¡Œ: **ç­”æ¡ˆç”Ÿæˆ** - ç”Ÿæˆå›ç­”...")
                        
                elif result.get("current_step") == "generation":
                    if result.get("step_state") == "running":
                        progress_placeholder.markdown("ğŸ”„ æ­£åœ¨æ‰§è¡Œ: **ç­”æ¡ˆç”Ÿæˆ** - ç”Ÿæˆå›ç­”...")
                        # å¤„ç†æµå¼ç­”æ¡ˆå—
                        if result.get("answer_chunk"):
                            current_answer = result.get("answer_partial", current_answer + result["answer_chunk"])
                            answer_placeholder.markdown(current_answer + "â–Œ")
                    elif result.get("step_state") == "completed":
                        progress_placeholder.markdown("âœ… å·²å®Œæˆ: **ç­”æ¡ˆç”Ÿæˆ**")
                        
                elif result.get("current_step") == "completion":
                    if result.get("step_state") == "completed":
                        # å¤„ç†å®Œæˆï¼Œæ¸…é™¤è¿›åº¦æŒ‡ç¤ºå™¨
                        progress_placeholder.empty()
                        
                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
                if result.get("is_final"):
                    final_result = result
                    current_answer = result.get("answer", current_answer)
                    answer_placeholder.markdown(current_answer)
                    # æ¸…é™¤è¿›åº¦æŒ‡ç¤ºå™¨
                    progress_placeholder.empty()
                    break
                    
                # å¤„ç†é”™è¯¯
                if result.get("error"):
                    progress_placeholder.markdown(f"âŒ æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    return
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            if final_result or current_answer:
                # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœä½†æœ‰ç­”æ¡ˆï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç»“æœç»“æ„
                if not final_result:
                    final_result = {"answer": current_answer, "documents": []}
                
                # æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºæ¥æº
                sources = format_document_sources(final_result.get("documents", []))
                
                if sources:
                    with sources_placeholder.expander("ğŸ“š å‚è€ƒæ¥æº"):
                        for i, source in enumerate(sources, 1):
                            st.markdown(
                                f"**{i}. {source['title']}** (ç›¸ä¼¼åº¦: {source['score']:.2f})"
                            )
                            st.markdown(f"> {source['content']}")
                            st.divider()
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": final_result.get("answer", current_answer),
                        "sources": sources,
                    }
                )
                
        except Exception as e:
            progress_placeholder.markdown(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"Streaming response error: {e}", exc_info=True)


def render_intermediate_results(
    result: Dict[str, Any], show_document_content: bool
) -> None:
    """æ¸²æŸ“ä¸­é—´ç»“æœ"""
    if "intermediate_results" not in result:
        return

    with st.expander("ğŸ”§ ç»„ä»¶æ‰§è¡Œè¿‡ç¨‹", expanded=True):
        for comp_name, comp_result in result["intermediate_results"].items():
            st.subheader(f"ğŸ“¦ {comp_name} ({comp_result['component_type']})")

            output = comp_result["output"]

            if comp_name == "es_retriever":
                render_retriever_results(output, show_document_content)
            elif comp_name == "zhipu_reranker":
                render_reranker_results(output, show_document_content)
            elif comp_name == "openai_generator":
                render_generator_results(output, show_document_content)

            # æ˜¾ç¤ºåŸå§‹æ•°æ®
            with st.expander(f"ğŸ” åŸå§‹æ•°æ® - {comp_name}", expanded=False):
                st.json(
                    {
                        "input": comp_result["input"],
                        "output": comp_result["output"],
                    }
                )

            st.divider()


def render_retriever_results(
    output: Dict[str, Any], show_document_content: bool
) -> None:
    """æ¸²æŸ“æ£€ç´¢å™¨ç»“æœ"""
    if "documents" in output:
        docs = output["documents"]
        st.success(f"âœ… æ£€ç´¢åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")

        if show_document_content:
            for i, doc in enumerate(docs[:5]):
                # è·å–å¬å›æ–¹å¼ä¿¡æ¯
                recall_source = doc.get('recall_source', 'unknown')
                recall_icon = "ğŸ“" if recall_source == "text" else "ğŸ¯" if recall_source == "vector" else "ğŸ”„"
                
                with st.expander(f"{recall_icon} æ–‡æ¡£ {i+1} (ç›¸ä¼¼åº¦: {doc.get('score', 0):.3f}) - {recall_source}å¬å›"):
                    st.write(f"**ID:** {doc.get('id', 'N/A')}")
                    
                    # æ˜¾ç¤ºå…³é”®è¯é«˜äº®ä¿¡æ¯
                    if 'highlights' in doc:
                        st.write("**ğŸ¯ å‘½ä¸­å…³é”®è¯:**")
                        highlights = doc['highlights']
                        for field, terms_info in highlights.items():
                            if isinstance(terms_info, dict) and 'relevant_terms' in terms_info:
                                relevant_terms = terms_info['relevant_terms']
                                if relevant_terms:
                                    st.write(f"  - **{field}**: {', '.join(relevant_terms)}")
                    
                    # æ˜¾ç¤ºå†…å®¹ï¼ˆä¿æŒåŸæœ‰çš„é«˜äº®æ ‡è®°ï¼‰
                    content = doc.get('content', '')[:500]
                    if '<mark>' in content:
                        # å°†HTMLæ ‡è®°è½¬æ¢ä¸ºStreamlitçš„markdowné«˜äº®
                        content = content.replace('<mark>', '**').replace('</mark>', '**')
                    st.write(f"**å†…å®¹:** {content}...")
                    
                    if doc.get("metadata"):
                        st.write(f"**å…ƒæ•°æ®:** {doc['metadata']}")
        else:
            for i, doc in enumerate(docs[:3]):
                recall_source = doc.get('recall_source', 'unknown')
                recall_icon = "ğŸ“" if recall_source == "text" else "ğŸ¯" if recall_source == "vector" else "ğŸ”„"
                
                # æ˜¾ç¤ºç®€åŒ–çš„å…³é”®è¯ä¿¡æ¯
                keywords_info = ""
                if 'highlights' in doc:
                    highlights = doc['highlights']
                    all_terms = []
                    for field, terms_info in highlights.items():
                        if isinstance(terms_info, dict) and 'relevant_terms' in terms_info:
                            all_terms.extend(terms_info['relevant_terms'])
                    if all_terms:
                        keywords_info = f" [å…³é”®è¯: {', '.join(set(all_terms))}]"
                
                content = doc.get('content', '')[:100]
                if '<mark>' in content:
                    content = content.replace('<mark>', '**').replace('</mark>', '**')
                    
                st.write(
                    f"**{recall_icon} æ–‡æ¡£ {i+1}** (å¾—åˆ†: {doc.get('score', 0):.3f}) - {content}...{keywords_info}"
                )


def render_reranker_results(
    output: Dict[str, Any], show_document_content: bool
) -> None:
    """æ¸²æŸ“é‡æ’å™¨ç»“æœ"""
    if "documents" in output:
        docs = output["documents"]
        st.success(f"âœ… é‡æ’åä¿ç•™ {len(docs)} ä¸ªæ–‡æ¡£")

        if show_document_content:
            for i, doc in enumerate(docs):
                with st.expander(
                    f"ğŸ“„ é‡æ’æ–‡æ¡£ {i+1} (é‡æ’å¾—åˆ†: {doc.get('score', 0):.3f})"
                ):
                    st.write(f"**å†…å®¹:** {doc.get('content', '')[:500]}...")
        else:
            for i, doc in enumerate(docs):
                st.write(
                    f"**é‡æ’æ–‡æ¡£ {i+1}** (å¾—åˆ†: {doc.get('score', 0):.3f}) - {doc.get('content', '')[:100]}..."
                )


def render_generator_results(
    output: Dict[str, Any], show_document_content: bool
) -> None:
    """æ¸²æŸ“ç”Ÿæˆå™¨ç»“æœ"""
    st.success("âœ… ç”Ÿæˆå›ç­”å®Œæˆ")
    if "context_used" in output:
        st.info(f"ğŸ“š ä½¿ç”¨äº† {output['context_used']} ä¸ªæ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡")

    if "documents" in output and show_document_content:
        with st.expander("ğŸ“‹ ç”Ÿæˆå™¨è¾“å…¥çš„æ–‡æ¡£å†…å®¹"):
            for i, doc in enumerate(output["documents"]):
                st.write(f"**è¾“å…¥æ–‡æ¡£ {i+1}:**")
                st.write(doc.get("content", "")[:300] + "...")
                st.divider()


def handle_non_streaming_response(
    prompt: str,
    top_k: int,
    search_type: str,
    show_intermediate: bool,
    show_document_content: bool,
) -> None:
    """å¤„ç†éæµå¼å“åº”"""
    with st.spinner("ğŸ” æ­£åœ¨æœç´¢å’Œç”Ÿæˆå›ç­”..."):
        result = search_with_pipeline(prompt, top_k, search_type, show_intermediate)

    if result.get("answer"):
        # æ˜¾ç¤ºä¸­é—´ç»“æœ
        if show_intermediate:
            render_intermediate_results(result, show_document_content)

        # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
        st.markdown(result["answer"])

        # å‡†å¤‡å’Œæ˜¾ç¤ºæ¥æºä¿¡æ¯
        sources = []
        if "documents" in result:
            sources = format_document_sources(result["documents"])

        render_sources(sources)

        # æ·»åŠ åˆ°å†å²è®°å½•
        st.session_state.messages.append(
            {
                "role": "assistant",
                "content": result["answer"],
                "sources": sources,
            }
        )
    else:
        error_msg = f"æŠ±æ­‰ï¼Œæœç´¢æ—¶å‡ºç°é”™è¯¯ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        st.error(error_msg)
        st.session_state.messages.append({"role": "assistant", "content": error_msg})


# ==================== ä¸»åº”ç”¨é€»è¾‘ ====================


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    # ä¸»ç•Œé¢æ ‡é¢˜
    st.title("ğŸ¤– RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    st.markdown("åŸºäºElasticsearchçš„çŸ¥è¯†æ£€ç´¢ä¸ç”Ÿæˆ")

    # æ¸²æŸ“ä¾§è¾¹æ é…ç½®
    search_type, top_k, output_mode, show_intermediate, show_document_content = (
        render_sidebar()
    )

    # æ˜¾ç¤ºå¯¹è¯å†å²
    render_chat_history()

    # èŠå¤©è¾“å…¥å¤„ç†
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # æ ¹æ®é…ç½®å†³å®šè¾“å‡ºæ¨¡å¼
        is_streaming = "æµå¼" in output_mode

        if is_streaming:
            # åœ¨ç”¨æˆ·æé—®å’ŒåŠ©æ‰‹å›å¤ä¹‹é—´åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
            progress_placeholder = st.empty()
            
            with st.chat_message("assistant"):
                handle_streaming_response_with_progress(prompt, top_k, search_type, progress_placeholder)
        else:
            with st.chat_message("assistant"):
                handle_non_streaming_response(
                    prompt, top_k, search_type, show_intermediate, show_document_content
                )

        # é‡æ–°è¿è¡Œé¡µé¢ä»¥æ˜¾ç¤ºæ–°æ¶ˆæ¯
        st.rerun()

    # é¡µé¢åº•éƒ¨ä¿¡æ¯
    st.divider()
    st.markdown(
        """
        <div style='text-align: center; color: #666; font-size: 12px;'>
            ğŸ’¡ æç¤ºï¼šä½ å¯ä»¥è¯¢é—®å…³äºæ€§èƒ½åˆ†æã€Linuxå·¥å…·ã€æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯é—®é¢˜
        </div>
        """,
        unsafe_allow_html=True,
    )


def handle_streaming_response_with_progress(
    prompt: str, top_k: int, search_type: str, progress_placeholder
) -> None:
    """å¤„ç†æµå¼å“åº”ï¼Œè¿›åº¦æ˜¾ç¤ºåœ¨ç‹¬ç«‹ä½ç½®"""
    # åˆ›å»ºå ä½ç¬¦
    answer_placeholder = st.empty()
    sources_placeholder = st.empty()
    
    # CSSåŠ¨ç”»æ ·å¼
    spinner_css = """
    <style>
    .spinner {
        display: inline-block;
        width: 16px;
        height: 16px;
        border: 2px solid #f3f3f3;
        border-top: 2px solid #3498db;
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-right: 8px;
    }
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    .progress-text {
        color: #666;
        font-size: 14px;
        display: flex;
        align-items: center;
    }
    </style>
    """
    
    try:
        # å¼€å§‹æœç´¢æµç¨‹
        progress_placeholder.markdown(
            spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨æ£€ç´¢æ–‡æ¡£...</div>', 
            unsafe_allow_html=True
        )
        
        # æ‰§è¡Œæœç´¢
        result_generator = search_with_pipeline_stream(prompt, top_k, search_type)
        
        final_result = None
        current_answer = ""
        
        for result in result_generator:
            # æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„å¤„ç†ä¸åŒé˜¶æ®µ
            if result.get("current_step") == "retrieval":
                if result.get("step_state") == "running":
                    progress_placeholder.markdown(
                        spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨æ£€ç´¢æ–‡æ¡£...</div>', 
                        unsafe_allow_html=True
                    )
                elif result.get("step_state") == "completed":
                    progress_placeholder.markdown(
                        spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨é‡æ’æ–‡æ¡£...</div>', 
                        unsafe_allow_html=True
                    )
                    
            elif result.get("current_step") == "rerank":
                if result.get("step_state") == "running":
                    progress_placeholder.markdown(
                        spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨é‡æ’æ–‡æ¡£...</div>', 
                        unsafe_allow_html=True
                    )
                elif result.get("step_state") == "completed":
                    progress_placeholder.markdown(
                        spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨ç”Ÿæˆå›ç­”...</div>', 
                        unsafe_allow_html=True
                    )
                    
            elif result.get("current_step") == "generation":
                if result.get("step_state") == "running":
                    progress_placeholder.markdown(
                        spinner_css + '<div class="progress-text"><div class="spinner"></div>æ­£åœ¨ç”Ÿæˆå›ç­”...</div>', 
                        unsafe_allow_html=True
                    )
                    # å¤„ç†æµå¼ç­”æ¡ˆå—
                    if result.get("answer_chunk"):
                        current_answer = result.get("answer_partial", current_answer + result["answer_chunk"])
                        answer_placeholder.markdown(current_answer + "â–Œ")
                elif result.get("step_state") == "completed":
                    # æ¸…é™¤è¿›åº¦æŒ‡ç¤ºå™¨
                    progress_placeholder.empty()
                    
            elif result.get("current_step") == "completion":
                if result.get("step_state") == "completed":
                    # å¤„ç†å®Œæˆï¼Œæ¸…é™¤è¿›åº¦æŒ‡ç¤ºå™¨
                    progress_placeholder.empty()
                    
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
            if result.get("is_final"):
                final_result = result
                current_answer = result.get("answer", current_answer)
                answer_placeholder.markdown(current_answer)
                # æ¸…é™¤è¿›åº¦æŒ‡ç¤ºå™¨
                progress_placeholder.empty()
                break
                
            # å¤„ç†é”™è¯¯
            if result.get("error"):
                progress_placeholder.markdown(
                    f'<div style="color: #ff6b6b; font-size: 14px;">âŒ å¤„ç†å¤±è´¥: {result.get("error", "æœªçŸ¥é”™è¯¯")}</div>', 
                    unsafe_allow_html=True
                )
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return
        
        # åœ¨å¾ªç¯ç»“æŸåå¤„ç†æœ€ç»ˆç»“æœï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
        if final_result or current_answer:
            # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœä½†æœ‰ç­”æ¡ˆï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç»“æœç»“æ„
            if not final_result:
                final_result = {"answer": current_answer, "documents": []}
            
            # æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºæ¥æº
            sources = format_document_sources(final_result.get("documents", []))
            
            if sources:
                with sources_placeholder.expander("ğŸ“š å‚è€ƒæ¥æº"):
                    for i, source in enumerate(sources, 1):
                        st.markdown(
                            f"**{i}. {source['title']}** (ç›¸ä¼¼åº¦: {source['score']:.2f})"
                        )
                        st.markdown(f"> {source['content']}")
                        st.divider()
            
            # æ·»åŠ åˆ°å†å²è®°å½•ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
            st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": final_result.get("answer", current_answer),
                    "sources": sources,
                }
            )
            
    except Exception as e:
        progress_placeholder.markdown(
            f'<div style="color: #ff6b6b; font-size: 14px;">âŒ å¤„ç†å¤±è´¥: {str(e)}</div>', 
            unsafe_allow_html=True
        )
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        logger.error(f"Streaming response error: {e}", exc_info=True)


if __name__ == "__main__":
    main()
