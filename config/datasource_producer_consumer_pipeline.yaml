# 数据源-生产者-消费者Pipeline配置
# 数据源: loader + splitter
# 生产者: embedding
# 消费者: indexer

datasource:
  components:
    document_loader:
      type: "loader"
      name: "file"
      config:
        path: "/Users/caixiaomeng/Projects/Python/EasyRAG/data/format_data_with_img"
        file_types: [".txt", ".md"]
        encoding: "utf-8"
        debug: true
    
    text_splitter:
      type: "splitter"
      name: "hierarchical"
      config:
        chunk_sizes: [1536, 512, 128]
        chunk_overlap: 50
        include_metadata: true
        max_chunk_size: 3072
        fallback_config:
          primary:
            type: "text"
            split_method: "character"
            chunk_size: 1024
            chunk_overlap: 100
            include_metadata: true
        debug: true
  
  flow:
    document_loader: ["text_splitter"]
    text_splitter: []
  
  entry_point: "document_loader"

producer:
  components:
    openai_embedding:
      type: "embedding"
      name: "openai"
      config:
        model: "models/bge-m3"
        api_key: "123456"
        api_base: "http://workspace.featurize.cn:38819/v1"
        batch_size: 50
        timeout: 60
        max_retries: 3
        debug: true
  
  flow:
    openai_embedding: []
  
  entry_point: "openai_embedding"

consumer:
  components:
    es_vector_indexer:
      type: "indexer"
      name: "elasticsearch"
      config:
        index_name: "vector_performance_docs"
        host: "localhost"
        port: 9200
        username: "elastic"
        password: "sPxLec=NGSFmUT_7+74R"
        use_ssl: true
        verify_certs: false
        batch_size: 100
        timeout: 30
        debug: true
        # ES jieba插件设置
        settings:
          number_of_shards: 1
          number_of_replicas: 0
          refresh_interval: "30s"
          translog:
            durability: "async"
          analysis:
            analyzer:
              ik_analyzer:
                type: "ik_max_word"
              ik_search_analyzer:
                type: "ik_smart"
        # 支持Small2Big的层级索引映射
        mapping:
          properties:
            content:
              type: "text"
              analyzer: "ik_analyzer"
              search_analyzer: "ik_search_analyzer"
            content_jieba:
              type: "text"
              analyzer: "ik_analyzer"
              search_analyzer: "ik_search_analyzer"
            content_vector:
              type: "dense_vector"
              dims: 1024
              index: true
              similarity: "cosine"
            metadata:
              type: "object"
              properties:
                source:
                  type: "text"
                  analyzer: "ik_analyzer"
                  fields:
                    keyword:
                      type: "keyword"
                file_path:
                  type: "text"
                  analyzer: "ik_analyzer"
                filename:
                  type: "keyword"
                  index: false
                file_type:
                  type: "keyword"
                chunk_index:
                  type: "integer"
                total_chunks:
                  type: "integer"
                chunk_size:
                  type: "integer"
                split_method:
                  type: "keyword"
                
                # Small2Big相关字段
                chunk_level:
                  type: "integer"          # chunk层级: 0=大, 1=中, 2=小
                parent_id:
                  type: "keyword"          # 父chunk的ID
                child_ids:
                  type: "keyword"          # 子chunk的ID列表
                  index: false
                root_id:
                  type: "keyword"          # 根chunk的ID
                hierarchy_path:
                  type: "keyword"          # 层级路径，如 "0/1/2"
                  index: false
                original_chunk_size:
                  type: "integer"          # 原始chunk大小配置
                  index: false
            timestamp:
              type: "date"
  
  flow:
    es_vector_indexer: []
  
  entry_point: "es_vector_indexer"
  
  # 消费者配置
  config:
    batch_size: 50
    max_queue_size: 2000
    producer_tasks: 4
    consumer_tasks: 4
    timeout: 30
    rate_limit_per_second: 100
    preload_all_data: true